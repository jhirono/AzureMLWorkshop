# Challenge 2: Refactor Model Training Code

Now you can successfully reproduce the safe driver prediction model using the notebook. The team would like to continue to ensure quality and improve the model code as well as centrally share models and results with others during development.  All of these goals are challenging with the training code embedded in a notebook and no centralized services are being utilized to facilitate sharing.  

What can be done to help the team with these goals?
Extracting the notebook code into Python scripts is an important step to ensure code quality via lint (covered in challenge 4) and unit tests and also cleanly execute on remote compute targets (covered in challenge 3).
Logging parameter values and model validation metrics centrally with the Azure Machine learning service makes it easy to compare the performance of different versions of the model and the parameters they were trained with.

## Prerequisites

Before starting this challenge, ensure you have the following prerequisite requirements in place from Challenge 1:

* An Azure Machine Learning workspace with a compute instance.
* The experimentation notebook provided by the data science team.

## Challenge

As a team, complete the following tasks:

1. Refactor the notebook code from Challenge 1 to create a Python script that uses the training data to train and evaluates the model, and saves the resulting model as with the name **lgbm_binary_model.pkl** in a folder named **outputs**. For an example notebook showing how to submit a script, look here: https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training/train-on-local/train-on-local.ipynb
1. In a new notebook, run the training script as an experiment and review the outputs generated by the experiment run in [Azure Machine Learning studio](https://ml.azure.com). The outputs should include the experiment run log files and the trained model.
1. Use an **Estimator** to run the script as an Azure Machine Learning experiment - base your code on the [Training Models](https://github.com/MicrosoftDocs/mslearn-aml-labs/blob/master/02-Training_Models.ipynb) exercise notebook for an example of running a training script with an estimator, logging metrics, and registering the resulting model using Azure ML Python SDK. This exercise is part of the Microsoft Learn *Train a machine learning model with Azure Machine Learning* module.
1. To run a script as an experiment, you should create a folder for the script file and copy the training data into this folder so that the script references the data using the appropriate relative path.
1. Specify a **'local'** compute target for running your experiment. In production, you would likely use a remote training cluster (to which the entire experiment folder would be copied automatically when the experiment is run), but remote compute can take a while to initialize so testing locally with this relatively small volume of data is generally quicker.
1. Modify your training script to:
    * Accept the **learning_rate** parameter as an argument, and use the argument value in the **parameters** dictionary used to train the model.
    * Log the **AUC** [(Area under the curve)](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5) evaluation metric in the experiment run, then each of the parameter values used to train the model.
        * [Documentation - How to monitor Azure ML experiment runs and metrics](https://docs.microsoft.com/azure/machine-learning/how-to-track-experiments)
1. Rerun the experiment, and verify that the metrics are logged.
1. Add code to your new notebook to retrieve the trained model from the experiment run, and register the model using Azure ML Python SDK with the name **lgbm_binary_model.pkl** in your Azure Machine Learning workspace  - using tags to record the **AUC** metric in the registration.

![Challenge 2 diagram](images/Diagrams-Chall-2.png)

### Hints

* To connect to your workspace from the Jupyter environment, best practice when using the Azure ML SDK is to use the `Workspace.from_config()` method to read the connection information from a workspace configuration file. On compute instances in your workspace, this file is created automatically. When using your own development environment, you must create this file in the same folder as your code. See [Configure a development environment for Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/how-to-configure-environment#workspace) for details.

### Success Criteria

To successfully complete this challenge, you must:

* Refactor the model training notebook to use the specified functions
* Refactor the model training notebook into separate python scripts that can be run independently of the notebook. The training script must contain arguments so that it can be used to train models with different parameters.
* Successfully run your experiment on Azure Machine Learning and be able to see the logged metrics and trained model in the run results.
* Successfully register the trained model.
* Discuss the following questions with your coach:
    * What is the benefit of separating the training code out of the notebook?
    * What is the benefit of running your experiments using Azure Machine Learning?

### Resources

* [Notebook: Training Models](https://github.com/MicrosoftDocs/mslearn-aml-labs/blob/master/02-Training_Models.ipynb)
* [*Microsoft Learn* module - Train a machine learning model with Azure Machine Learning](https://docs.microsoft.com/learn/modules/train-local-model-with-azure-mls/index)
* [Documentation - Train models with Azure machine Learning](https://docs.microsoft.com/azure/machine-learning/concept-train-machine-learning-model)
* [Documentation - How to build scikit-learn models at scale with Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/how-to-train-scikit-learn)

## Explore Further

In this solution, you used a local data file to train the model. To increase scalability and flexibility, you can store this data centrally in an Azure Machine Learning *datastore*, and you can create a *dataset* to simplify data ingestion and enable data versioning. See the following resources for more information:

* [Documentation - How to access data in Azure storage services](https://docs.microsoft.com/azure/machine-learning/how-to-access-data)
* [Documentation - How to create Azure Machine Learning datasets](https://docs.microsoft.com/azure/machine-learning/how-to-create-register-datasets)
* [Documentation - How to train with datasets](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-with-datasets)
* [Documnetation - How to deploy and where to connect to your workspace](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where#connect-to-your-workspace)
