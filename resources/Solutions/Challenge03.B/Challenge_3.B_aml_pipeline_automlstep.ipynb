{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning Pipeline with AutoMLStep (AutoML training in pipeline)\n",
    "This notebook demonstrates the use of **AutoMLStep** for training in Azure Machine Learning Pipeline.\n",
    "As secondary pipeline step, it also uses a **PythonScriptStep** for registering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this example we showcase how you can use AzureML Dataset to load data for AutoML via AML Pipeline. \n",
    "\n",
    "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you have executed the [configuration](https://aka.ms/pl-config) before running this notebook.\n",
    "\n",
    "In this notebook you will learn how to:\n",
    "1. Create an `Experiment` in an existing `Workspace`.\n",
    "2. Create or Attach existing AmlCompute to a workspace.\n",
    "3. Define data loading in a **TabularDataset**.\n",
    "4. Configure AutoML using **AutoMLConfig**.\n",
    "5. Configure **AutoMLStep** step for training\n",
    "6. Configure **PythonScriptStep** for registering the model in the Workspace\n",
    "6. Run the AML pipeline using AmlCompute\n",
    "7. Explore the results.\n",
    "8. Test the best fitted model.\n",
    "9. Publish the Pipeline in the Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Machine Learning and Pipeline SDK-specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import pkg_resources\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "from azureml.train.automl.runtime import AutoMLStep\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "Initialize a workspace object from persisted configuration. Make sure the config file is present at .\\config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure ML experiment\n",
    "Let's create an experiment named \"automl-classification\" and a folder to hold the training scripts. The script runs will be recorded under the experiment in Azure.\n",
    "\n",
    "The best practice is to use separate folders for scripts and its dependent files for each step and specify that folder as the `source_directory` for the step. This helps reduce the size of the snapshot created for the step (only the specific folder is snapshotted). Since changes in any files in the `source_directory` would trigger a re-upload of the snapshot, this helps keep the reuse of the step when there are no changes in the `source_directory` of the step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a name for the run history container in the workspace.\n",
    "experiment_name = 'automlstep-classif-porto'\n",
    "project_folder = './project'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Attach an AmlCompute cluster\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for your AutoML run. In this tutorial, you get the default `AmlCompute` as your training compute resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "# Define remote compute target to use\n",
    "# Further docs on Remote Compute Target: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-remote\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "amlcompute_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "found = False\n",
    "# Check if this compute target already exists in the workspace.\n",
    "cts = ws.compute_targets\n",
    "\n",
    "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n",
    "     found = True\n",
    "     print('Found existing training cluster.')\n",
    "     # Get existing cluster\n",
    "     # Method 1:\n",
    "     aml_remote_compute = cts[amlcompute_cluster_name]\n",
    "     # Method 2:\n",
    "     # aml_remote_compute = ComputeTarget(ws, amlcompute_cluster_name)\n",
    "    \n",
    "if not found:\n",
    "     print('Creating a new training cluster...')\n",
    "     provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D13_V2\", # for GPU, use \"STANDARD_NC12\"\n",
    "                                                                 #vm_priority = 'lowpriority', # optional\n",
    "                                                                 max_nodes = 6)\n",
    "     # Create the cluster.\n",
    "     aml_remote_compute = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
    "    \n",
    "print('Checking cluster status...')\n",
    "# Can poll for a minimum number of nodes and for a specific timeout.\n",
    "# If no min_node_count is provided, it will use the scale settings for the cluster.\n",
    "aml_remote_compute.wait_for_completion(show_output = True, min_node_count = 0, timeout_in_minutes = 20)\n",
    "\n",
    "# For a more detailed view of current AmlCompute status, use get_status()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (***Optional***) Submit dataset file into DataStore (Azure Blob under the covers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload(src_dir='../../../data/', \n",
    "                 target_path='Datasets/porto_seguro_safe_driver_prediction', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into Azure ML Dataset and Register into Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load the dataset from the Workspace. Otherwise, create it from the file in the HTTP URL\n",
    "found = False\n",
    "aml_dataset_name = \"porto_seguro_safe_driver_prediction_train\"\n",
    "\n",
    "if aml_dataset_name in ws.datasets.keys(): \n",
    "       found = True\n",
    "       dataset = ws.datasets[aml_dataset_name] \n",
    "       print(\"Dataset found and loaded from the Workspace\")\n",
    "       \n",
    "if not found:\n",
    "        # Create AML Dataset and register it into Workspace\n",
    "        print(\"Dataset does not exist in the current Workspace. It will be imported and registered.\")\n",
    "        \n",
    "        # Option A: Create AML Dataset from file in AML DataStore\n",
    "        datastore = ws.get_default_datastore()\n",
    "        dataset = Dataset.Tabular.from_delimited_files(path=datastore.path('Datasets/porto_seguro_safe_driver_prediction/porto_seguro_safe_driver_prediction_train.csv'))\n",
    "        data_origin_type = 'AMLDataStore'\n",
    "        \n",
    "        # Option B: Create AML Dataset from file in HTTP URL\n",
    "        # data_url = 'https://url/porto_seguro_safe_driver_prediction_train.csv'\n",
    "        # aml_dataset = Dataset.Tabular.from_delimited_files(data_url)  \n",
    "        # data_origin_type = 'HttpUrl'\n",
    "        \n",
    "        print(aml_dataset)\n",
    "                \n",
    "        #Register Dataset in Workspace\n",
    "        registration_method = 'SDK'  # or 'UI'\n",
    "        dataset = aml_dataset.register(workspace=ws,\n",
    "                                           name=aml_dataset_name,\n",
    "                                           description='Porto Seguro Safe Driver Prediction Train dataset file',\n",
    "                                           tags={'Registration-Method': registration_method, 'Data-Origin-Type': data_origin_type},\n",
    "                                           create_new_version=True)\n",
    "        \n",
    "        print(\"Dataset created from file and registered in the Workspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.take(1).to_pandas_dataframe().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.take(5).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segregate a Test dataset for later testing and creating a confusion matrix\n",
    "Split original AML Tabular Dataset in two test/train AML Tabular Datasets (using AML DS function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name and target column of the Dataset to create \n",
    "train_dataset_name = \"porto_seguro_safe_driver_prediction_train90\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split using Azure Tabular Datasets (Better for Remote Compute)\n",
    "# https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.tabulardataset?view=azure-ml-py#random-split-percentage--seed-none-\n",
    "\n",
    "train_dataset, test_dataset = dataset.random_split(0.9, seed=1)\n",
    "\n",
    "#Register Train Dataset (90%) after Split in Workspace\n",
    "registration_method = 'SDK'  # or 'UI'\n",
    "data_origin_type = 'SPLIT'\n",
    "train_dataset = train_dataset.register(workspace=ws,\n",
    "                                       name=train_dataset_name,\n",
    "                                       description='Porto Seguro Safe Driver Prediction Train dataset file (90%)',\n",
    "                                       tags={'Registration-Method': registration_method, 'Data-Origin-Type': data_origin_type},\n",
    "                                       create_new_version=True)\n",
    "\n",
    "# Load from Workspace\n",
    "train_dataset = ws.datasets[train_dataset_name] \n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List possible metrics to optimize for (primary metric) in Classification using AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train import automl\n",
    "\n",
    "# List of possible primary metrics is here:\n",
    "# https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#primary-metric\n",
    "    \n",
    "# Get a list of valid metrics for your given task\n",
    "automl.utilities.get_primary_metrics('classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train configuration in AutoMLConfig\n",
    "This creates a general AutoML settings object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can provide additional settings as a **kwargs parameter for the AutoMLConfig object\n",
    "automl_settings = {\n",
    "     \"whitelist_models\": ['LightGBM']\n",
    "}\n",
    "\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "automl_config = AutoMLConfig(compute_target=aml_remote_compute,\n",
    "                             task='classification',\n",
    "                             primary_metric='AUC_weighted',                            \n",
    "                             training_data=train_dataset,\n",
    "                             # validation_data=validation_dataset,\n",
    "                             path = project_folder,\n",
    "                             label_column_name=\"target\",\n",
    "                             enable_early_stopping= True,\n",
    "                             # blacklist_models=['LinearSVMClassifier', 'MultinomialNaiveBayes'], \n",
    "                             # iteration_timeout_minutes= 5,                        \n",
    "                             # experiment_exit_score= 0.65,\n",
    "                             iterations=1,\n",
    "                             featurization= 'auto',\n",
    "                             debug_log='automated_ml_errors.log',\n",
    "                             verbosity= logging.INFO,\n",
    "                             enable_onnx_compatible_models=False,\n",
    "                             **automl_settings\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The AML Pipeline\n",
    "\n",
    "### PipelineData objects\n",
    "\n",
    "The **PipelineData** object is a special kind of data reference that is used for interim storage locations that can be passed between pipeline steps, so we'll create one and use at as the output for the first step and the input for the second step. Note that we also need to pass it as a script argument so our code can access the datastore location referenced by the data reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "metrics_output_name = 'metrics_output'\n",
    "best_model_output_name = 'best_model_output'\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                            datastore=ds,\n",
    "                            pipeline_output_name=metrics_output_name,\n",
    "                            training_output=TrainingOutput(type='Metrics'))\n",
    "\n",
    "model_data = PipelineData(name='model_data',\n",
    "                          datastore=ds,\n",
    "                          pipeline_output_name=best_model_output_name,\n",
    "                          training_output=TrainingOutput(type='Model'))\n",
    "\n",
    "print(model_data.get_env_variable_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an AutoMLStep for training.\n",
    "Pipelines consist of one or more *steps*, which can be Python scripts, or specialized steps like an AutoMLStep for training or a data transfer step that copies data from one location to another. \n",
    "Each step can run in its own compute context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_step = AutoMLStep(\n",
    "    name='automl_module',\n",
    "    automl_config=automl_config,\n",
    "    outputs=[metrics_data, model_data],\n",
    "    allow_reuse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a PythonScriptStep to register the model in the Workspace.\n",
    "\n",
    "Write/save the Python code to register the model in a file named register_model.py\n",
    "The script for the second step of the pipeline will load the model from where it was saved, and then register it in the workspace. It includes a single **model_folder** parameter that contains the path where the model was saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment, Conda-Dependencies and RunConfiguration for PythonScriptStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import CondaDependencies, DEFAULT_CPU_IMAGE, RunConfiguration\n",
    "\n",
    "# Create an Environment for future usage\n",
    "custom_env = Environment(\"python-script-step-env\")\n",
    "custom_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "custom_env.docker.enabled = True \n",
    "custom_env.docker.base_image = azureml.core.runconfig.DEFAULT_CPU_IMAGE \n",
    "\n",
    "conda_dependencies = CondaDependencies.create(pip_packages=['azureml-sdk[automl]', 'applicationinsights'], #'azureml-explain-model'\n",
    "                                              conda_packages=['numpy==1.16.2'], \n",
    "                                              pin_sdk_version=False)\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "custom_env.python.conda_dependencies = conda_dependencies\n",
    "\n",
    "# Register the environment (To use it again)\n",
    "custom_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'python-script-step-env')\n",
    "\n",
    "# create a new RunConfig object\n",
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# Set compute target to AmlCompute\n",
    "conda_run_config.target = aml_remote_compute\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "conda_run_config.environment\n",
    "conda_run_config.environment = registered_env\n",
    "\n",
    "print('Run config is ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Model Step\n",
    "Script to register the model to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "scripts_folder=\"Scripts\"\n",
    "os.makedirs(scripts_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the register_model.py script file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $scripts_folder/register_model.py\n",
    "from azureml.core.model import Model, Dataset\n",
    "from azureml.core.run import Run, _OfflineRun\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_name\")\n",
    "parser.add_argument(\"--model_path\")\n",
    "parser.add_argument(\"--ds_name\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(\"Argument 1(model_name): %s\" % args.model_name)\n",
    "print(\"Argument 2(model_path): %s\" % args.model_path)\n",
    "print(\"Argument 3(ds_name): %s\" % args.ds_name)\n",
    "\n",
    "run = Run.get_context()\n",
    "ws = None\n",
    "if type(run) == _OfflineRun:\n",
    "    ws = Workspace.from_config()\n",
    "else:\n",
    "    ws = run.experiment.workspace\n",
    "\n",
    "train_ds = Dataset.get_by_name(ws, args.ds_name)\n",
    "datasets = [(Dataset.Scenario.TRAINING, train_ds)]\n",
    "\n",
    "# Register model with training dataset\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "                       model_path=args.model_path,                  # File to upload and register as a model.\n",
    "                       model_name=args.model_name,                  # Name of the registered model in your workspace.\n",
    "                       datasets=datasets,\n",
    "                       description='Porto Seguro Safe Driving Prediction.',\n",
    "                       tags={'area': 'insurance', 'type': 'classification'}\n",
    "                      )\n",
    "\n",
    "print(\"Registered version {0} of model {1}\".format(model.version, model.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PythonScriptStep to run register_model.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineParameter\n",
    "\n",
    "# The model name with which to register the trained model in the workspace.\n",
    "model_name = \"porto-model-from-automlstep\"\n",
    "model_name_param = PipelineParameter(\"model_name\", default_value=model_name)\n",
    "\n",
    "# The Dataset name to relate with the model to register in the workspace.\n",
    "dataset_name_param = PipelineParameter(name=\"ds_name\", default_value=train_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PythonScriptStep for Model registration\n",
    "\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "register_model_step = PythonScriptStep(name=\"register_model\",                                      \n",
    "                                       source_directory = scripts_folder,            # Local folder with .py script\n",
    "                                       script_name=\"register_model.py\",\n",
    "                                       allow_reuse=False,\n",
    "                                       arguments=[\"--model_name\", model_name_param, \"--model_path\", model_data, \"--ds_name\", dataset_name_param],\n",
    "                                       inputs=[model_data],\n",
    "                                       compute_target=aml_remote_compute,\n",
    "                                       runconfig=conda_run_config)\n",
    "\n",
    "register_model_step.run_after(automl_step)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example, designed to demonstrate the principle. In reality, you could build more sophisticated logic into the pipeline steps - for example, evaluating the model against some test data to calculate a performance metric like AUC or accuracy, comparing the metric to that of any previously registered versions of the model, and only registering the new model if it performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline and add the multiple steps into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "pipeline = Pipeline(\n",
    "    description=\"pipeline_with_automlstep\",\n",
    "    workspace=ws,    \n",
    "    steps=[automl_step, register_model_step]) \n",
    "\n",
    "print(\"Pipeline is built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run = experiment.submit(pipeline, pipeline_parameters={\n",
    "        \"ds_name\": train_dataset_name, \"model_name\": model_name})\n",
    "\n",
    "print(\"Pipeline submitted for execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Results from Pipeline\n",
    "\n",
    "### Retrieve the metrics of all child runs\n",
    "Outputs of above run can be used as inputs of other steps in pipeline. In this tutorial, we will examine the outputs by retrieve output data and running some tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_output = pipeline_run.get_pipeline_output(metrics_output_name)\n",
    "num_file_downloaded = metrics_output.download('.', show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(metrics_output._path_on_datastore) as f:  \n",
    "   metrics_output_result = f.read()\n",
    "    \n",
    "deserialized_metrics_output = json.loads(metrics_output_result)\n",
    "df = pd.DataFrame(deserialized_metrics_output)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve info about the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_run.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_output = pipeline_run.get_pipeline_output(best_model_output_name)\n",
    "best_model_output\n",
    "# num_file_downloaded = best_model_output.download('.', show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_output = pipeline_run.get_pipeline_output(best_model_output_name)\n",
    "num_file_downloaded = best_model_output.download('.', show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(best_model_output._path_on_datastore, \"rb\" ) as f:\n",
    "    best_model = pickle.load(f)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "#### Load Test Data\n",
    "For the test data, it should have the same preparation step as the train data. Otherwise it might get failed at the preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_test = Dataset.Tabular.from_delimited_files(path='https://url/dataset-test.csv')\n",
    "test_df = test_dataset.to_pandas_dataframe()\n",
    "print(test_df.shape)\n",
    "\n",
    "test_df = test_df[pd.notnull(test_df['target'])]\n",
    "\n",
    "if 'target' in test_df.columns:\n",
    "    y_test = test_df[['target']]\n",
    "    X_test = test_df.drop(['target'], axis=1)\n",
    "\n",
    "# Method 2:\n",
    "# if 'target' in test_df.columns:\n",
    "#     y_test = test_df.pop('target')\n",
    "#\n",
    "# X_test = test_df\n",
    "\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Our Best Fitted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the best model making predictions with the test dataset\n",
    "y_predictions = best_model.predict(X_test)\n",
    "\n",
    "print('10 predictions: ')\n",
    "print(y_predictions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy with Scikit-Learn model:')\n",
    "print(accuracy_score(y_test, y_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate AUC with Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_predictions)\n",
    "print('AUC (Area Under the Curve) with Test dataset:')\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Confusion Matrix\n",
    "We will use confusion matrix to see how our model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "cm = ConfusionMatrix(y_test['target'], y_predictions)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "cm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the Pipeline\n",
    "Now that you've created a pipeline and verified it works, you can publish it as a REST service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline.publish(name=\"Training_Pipeline_AutoMLStep_Porto\",\n",
    "                                      description=\"Pipeline with AutoMLStep for Training model for Porto Seguro Safe Driver\")\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigger the AML Pipeline by using the Pipeline REST Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. A real application would require a service principal with which to be authenticated, but to test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print(auth_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to call the REST interface. The pipeline runs asynchronously, so you'll get an identifier back, which you can use to track the pipeline experiment as it runs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The REST Endpoint\n",
    "Note that the published pipeline has an endpoint, which you can see in the Endpoints page (on the Pipeline Endpoints tab) in Azure Machine Learning studio. You can also find its URI as a property of the published pipeline object.\n",
    "So, you could also copy that REST Endpoint from the AML portal and paste it like here:\n",
    "\n",
    "rest_endpoint = \"Your opied REST Endpoint here\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you have the run ID, you can use the RunDetails widget to view the experiment as it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
    "RunDetails(published_pipeline_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps!\n",
    "You can use the Azure Machine Learning extension for Azure DevOps to combine Azure ML pipelines with Azure DevOps pipelines (yes, it is confusing that they have the same name!) and integrate model retraining into a continuous integration/continuous deployment (CI/CD) process. For example you could use an Azure DevOps build pipeline to trigger an Azure ML pipeline that trains and registers a model, and when the model is registered it could trigger an Azure Devops release pipeline that deploys the model as a web service, along with the application or service that consumes the model."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "sanpil"
   }
  ],
  "category": "tutorial",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "Custom"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "Automated Machine Learning"
  ],
  "friendly_name": "How to use AutoMLStep with AML Pipelines",
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "order_index": 11,
  "star_tag": [
   "featured"
  ],
  "tags": [
   "None"
  ],
  "task": "Demonstrates the use of AutoMLStep"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
