{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Pipeline\n",
    "\n",
    "In the previous labs, you used the Azure Machine Learning SDK to explore the entire model training process from accessing data through to running training experiments and registering machine learning models. Up until now, you have performed the various steps required to create a machine learning solution interactively. In this lab, you'll explore automation of these steps using *pipelines*.\n",
    "\n",
    "## Connect to Your Workspace\n",
    "\n",
    "The first thing you need to do is to connect to your workspace using the Azure ML SDK.\n",
    "\n",
    "> **Note**: If the authenticated session with your Azure subscription has expired since you completed the previous exercise, you'll be prompted to reauthenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for this example your training folder should contain your training script as well as training data \n",
    "training_folder=\"Scripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cesardl-automl-ncentralus-demo-ws\n",
      "cesardl-automl-ncentralus-demo-ws-resgrp\n",
      "northcentralus\n",
      "381b38e9-9840-4719-a5a0-61d9585e1e91\n",
      "Ready to use Azure ML 1.0.83 to work with cesardl-automl-ncentralus-demo-ws\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
    "\n",
    "# Explicit Workspace config:\n",
    "# workspace_name=\"\"\n",
    "# subscription_id=\"\"\n",
    "# resource_group=\"\"\n",
    "\n",
    "# ws = Workspace.get(\n",
    "#    name=workspace_name,\n",
    "#    subscription_id=subscription_id,\n",
    "#    resource_group=resource_group)\n",
    "\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Scripts for Pipeline Steps\n",
    "\n",
    "Pipelines consist of one or more *steps*, which can be Python scripts, or specialized steps like an Auto ML training estimator or a data transfer step that copies data from one location to another. Each step can run in its own compute context.\n",
    "\n",
    "In this exercise, you'll build a simple pipeline that contains an estimator step (to train a model) and a Python script step (to register the trained model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "os.makedirs(training_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script for the second step of the pipeline will load the model from where it was saved, and then register it in the workspace. It includes a single **model_folder** parameter that contains the path where the model was saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Scripts/register_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/register_model.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Workspace, Model, Run\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_folder', type=str, dest='model_folder')\n",
    "args = parser.parse_args()\n",
    "model_folder = args.model_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the model\n",
    "print(\"Loading model from \" + model_folder)\n",
    "model_file = model_folder + \"/model.pkl\"\n",
    "model = joblib.load(model_file)\n",
    "\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path = model_file,\n",
    "               model_name = 'model',\n",
    "               tags={'Training context':'Pipeline'})\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a Compute Environment for the Pipeline Steps\n",
    "\n",
    "In this exercise, you'll use the same compute for both steps, but it's important to realize that each step is run independently; so you could specify different compute contexts for each step if appropriate.\n",
    "\n",
    "First, get the compute target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"aml-cluster\"\n",
    "\n",
    "# Verify that cluster exists\n",
    "try:\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If not, create it\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', \n",
    "                                                           vm_priority='lowpriority', \n",
    "                                                           max_nodes=4)\n",
    "    pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "pipeline_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compute will require a Python environment with the necessary package dependencies installed, so we'll create a run configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "env = Environment(\"pipeline-experiment-env\")\n",
    "env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "env.docker.enabled = True # Use a docker container\n",
    "\n",
    "# Create a set of package dependencies\n",
    "dependencies = CondaDependencies.create(conda_packages=['scikit-learn', 'pandas'],\n",
    "                                             pip_packages=['azureml-sdk','lightgbm'])\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "env.python.conda_dependencies = dependencies\n",
    "\n",
    "# Register the environment (just in case previous lab wasn't completed)\n",
    "env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'pipeline-experiment-env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Run a Pipeline\n",
    "\n",
    "Now we're ready to create and run a pipeline.\n",
    "\n",
    "First we need to define the steps for the pipeline, and any data references that need to passed between them. In this case, the first step must write the model to a folder that can be read from by the second step. Since the steps will be run on remote compute (and in fact, could each be run on different compute), the folder path must be passed as a data reference to a location in a datastore within the workspace. The **PipelineData** object is a special kind of data reference that is used for interim storage locations that can be passed between pipeline steps, so we'll create one and use at as the output for the first step and the input for the second step. Note that we also need to pass it as a script argument so our code can access the datastore location referenced by the data reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference) for the model folder\n",
    "model_folder = PipelineData(\"model_folder\", datastore=ws.get_default_datastore())\n",
    "\n",
    "estimator = Estimator(source_directory=training_folder,\n",
    "                        compute_target = pipeline_cluster,\n",
    "                        environment_definition=pipeline_run_config.environment,\n",
    "                        entry_script='train.py')\n",
    "\n",
    "train_step = EstimatorStep(name = \"Train Model\",\n",
    "                           estimator=estimator, \n",
    "                           estimator_entry_script_arguments=['--output_folder', model_folder],\n",
    "                           outputs=[model_folder],\n",
    "                           compute_target = pipeline_cluster,\n",
    "                           allow_reuse = True)\n",
    "\n",
    "# Step 2, run the model registration script\n",
    "register_step = PythonScriptStep(name = \"Register Model\",\n",
    "                                source_directory = training_folder,\n",
    "                                script_name = \"register_model.py\",\n",
    "                                arguments = ['--model_folder', model_folder],\n",
    "                                inputs=[model_folder],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "register_step.run_after(train_step)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, we're ready to go. let's build the pipeline from the steps we've defined and run it as an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n",
      "Created step Train Model [ecccd0be][57efcc96-0836-433c-b690-32e903625f3f], (This step will run and generate new outputs)Created step Register Model [37997c00][ae9f9f79-d68b-49fb-bd47-1752b565914b], (This step will run and generate new outputs)\n",
      "\n",
      "Created step Train Model [ecccd0be][85d10e85-0604-4d48-8673-5900f6cf4c69], (This step will run and generate new outputs)\n",
      "Created step Register Model [37997c00][4ab5111f-5933-496e-9507-5b9356d51725], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 182537d0-76e1-457f-8bc5-946be4203d12\n",
      "Link to Azure Machine Learning studio: https://ml.azure.com/experiments/training-pipeline/runs/182537d0-76e1-457f-8bc5-946be4203d12?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec7e0ce58b1418c81beb898cb595837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Failed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/training-pipeline/runs/182537d0-76e1-457f-8bc5-946be4203d12?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\", \"run_id\": \"182537d0-76e1-457f-8bc5-946be4203d12\", \"run_properties\": {\"run_id\": \"182537d0-76e1-457f-8bc5-946be4203d12\", \"created_utc\": \"2020-03-01T21:02:44.762402Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2020-03-01T21:04:45.566379Z\", \"status\": \"Failed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.182537d0-76e1-457f-8bc5-946be4203d12/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=ou8KvlBVdhH9Aob%2FnjdaBO8c5DFBcppIM78DYxdO1%2Bg%3D&st=2020-03-01T20%3A54%3A56Z&se=2020-03-02T05%3A04%3A56Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.182537d0-76e1-457f-8bc5-946be4203d12/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=eme6FvNSvbpVOr%2BYnvi3q%2FQ9Ju70XUELcrvkDdKArUU%3D&st=2020-03-01T20%3A54%3A56Z&se=2020-03-02T05%3A04%3A56Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.182537d0-76e1-457f-8bc5-946be4203d12/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=c4vp65zaLF%2BOxN0IMbyL8Wk%2B2rm4fLW8hjF9LABsgys%3D&st=2020-03-01T20%3A54%3A56Z&se=2020-03-02T05%3A04%3A56Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:02:00\"}, \"child_runs\": [{\"run_id\": \"95f2c341-21d2-4dc5-837e-5613c465f285\", \"name\": \"Train Model\", \"status\": \"Failed\", \"start_time\": \"2020-03-01T21:03:47.290307Z\", \"created_time\": \"2020-03-01T21:02:49.935105Z\", \"end_time\": \"2020-03-01T21:04:39.689351Z\", \"duration\": \"0:01:49\", \"run_number\": 4, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-03-01T21:02:49.935105Z\", \"is_reused\": \"\"}, {\"run_id\": \"\", \"name\": \"Register Model\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2020-03-01 21:02:49Z] Submitting 1 runs, first five are: ecccd0be:95f2c341-21d2-4dc5-837e-5613c465f285\\n[2020-03-01 21:04:45Z] Execution of experiment failed, update experiment status and cancel running nodes.\\n\", \"graph\": {\"datasource_nodes\": {}, \"module_nodes\": {\"ecccd0be\": {\"node_id\": \"ecccd0be\", \"name\": \"Train Model\", \"status\": \"Failed\", \"_is_reused\": false, \"run_id\": \"95f2c341-21d2-4dc5-837e-5613c465f285\"}, \"37997c00\": {\"node_id\": \"37997c00\", \"name\": \"Register Model\", \"status\": \"NotStarted\"}}, \"edges\": [{\"source_node_id\": \"ecccd0be\", \"source_node_name\": \"Train Model\", \"source_name\": \"model_folder\", \"target_name\": \"model_folder\", \"dst_node_id\": \"37997c00\", \"dst_node_name\": \"Register Model\"}, {\"source_node_id\": \"ecccd0be\", \"source_node_name\": \"Train Model\", \"source_name\": \"model_folder\", \"target_name\": \"model_folder\", \"dst_node_id\": \"37997c00\", \"dst_node_name\": \"Register Model\"}], \"child_runs\": [{\"run_id\": \"95f2c341-21d2-4dc5-837e-5613c465f285\", \"name\": \"Train Model\", \"status\": \"Failed\", \"start_time\": \"2020-03-01T21:03:47.290307Z\", \"created_time\": \"2020-03-01T21:02:49.935105Z\", \"end_time\": \"2020-03-01T21:04:39.689351Z\", \"duration\": \"0:01:49\", \"run_number\": 4, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-03-01T21:02:49.935105Z\", \"is_reused\": \"\"}, {\"run_id\": \"\", \"name\": \"Register Model\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.83\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 182537d0-76e1-457f-8bc5-946be4203d12\n",
      "Link to Portal: https://ml.azure.com/experiments/training-pipeline/runs/182537d0-76e1-457f-8bc5-946be4203d12?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 95f2c341-21d2-4dc5-837e-5613c465f285\n",
      "Link to Portal: https://ml.azure.com/experiments/training-pipeline/runs/95f2c341-21d2-4dc5-837e-5613c465f285?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\n",
      "StepRun( Train Model ) Status: NotStarted\n",
      "StepRun( Train Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_c1da901410239e55c40c6c5f877d10417e227c13bbdcdf22a3cd6d97e300df91_p.txt\n",
      "========================================================================================================================\n",
      "2020-03-01T21:03:37Z Starting output-watcher...\n",
      "2020-03-01T21:03:37Z IsDedicatedCompute == False, starting polling for Low-Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_c8150e2254065263b538e03af53c2838\n",
      "Digest: sha256:7561b96a1800349b27f2da89326ca9f7b648d358566d70b8bfd95a132e64a409\n",
      "Status: Image is up to date for cesardlautoma5f87185.azurecr.io/azureml/azureml_c8150e2254065263b538e03af53c2838:latest\n",
      "41251515161ea040bcfd8faec01c5e3e7181a9469e79f7b732e62293fbd5b06b\n",
      "2020/03/01 21:03:39 Version: 3.0.01150.0001 Branch: master Commit: d0a02aae\n",
      "2020/03/01 21:03:40 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/03/01 21:03:40 sshd runtime has already been installed in the container\n",
      "ssh-keygen: /azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "bash: /azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "bash: /azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_c1da901410239e55c40c6c5f877d10417e227c13bbdcdf22a3cd6d97e300df91_p.txt\n",
      "===============================================================================================================\n",
      "bash: /azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting job preparation. Current time:2020-03-01T21:03:51.231405\n",
      "Extracting the control code.\n",
      "Creating directory: azureml-logs/\n",
      "Retrieving project from snapshot: bfe9b72b-f4d1-446f-9b41-970bef2374ba\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 86\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "Download from datastores if requested.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "bash: /azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "bash: /azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 141\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ train.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/95f2c341-21d2-4dc5-837e-5613c465f285/mounts/workspaceblobstore/azureml/95f2c341-21d2-4dc5-837e-5613c465f285/model_folder']\n",
      "After variable expansion, calling script [ train.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/95f2c341-21d2-4dc5-837e-5613c465f285/mounts/workspaceblobstore/azureml/95f2c341-21d2-4dc5-837e-5613c465f285/model_folder']\n",
      "\n",
      "(595212, 59)\n",
      "\n",
      "\n",
      "The experiment failed. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.0021064281463623047 seconds\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 141\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 118, in <module>\n",
      "    X_train, X_test = X.ix[train_index], X.ix[test_index]\n",
      "  File \"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/site-packages/pandas/core/generic.py\", line 5274, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "AttributeError: 'DataFrame' object has no attribute 'ix'\n",
      "\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_c1da901410239e55c40c6c5f877d10417e227c13bbdcdf22a3cd6d97e300df91_p.txt\n",
      "===============================================================================================================\n",
      "bash: /azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting job release. Current time:2020-03-01T21:04:21.120460\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 191\n",
      "Job release is complete. Current time:2020-03-01T21:04:23.326140\n",
      "\n",
      "StepRun(Train Model) Execution Summary\n",
      "=======================================\n",
      "StepRun( Train Model ) Status: Failed\n",
      "\n",
      "Warnings:\n",
      "{\n",
      "  \"error\": {\n",
      "    \"code\": \"UserError\",\n",
      "    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\",\n",
      "    \"messageFormat\": null,\n",
      "    \"messageParameters\": {},\n",
      "    \"referenceCode\": null,\n",
      "    \"detailsUri\": null,\n",
      "    \"target\": null,\n",
      "    \"details\": [],\n",
      "    \"innerError\": null,\n",
      "    \"debugInfo\": null\n",
      "  },\n",
      "  \"correlation\": {\n",
      "    \"operation\": null,\n",
      "    \"request\": \"d2590053c34c38c9\"\n",
      "  },\n",
      "  \"environment\": \"northcentralus\",\n",
      "  \"location\": \"northcentralus\",\n",
      "  \"time\": \"2020-03-01T21:04:39.5431195+00:00\"\n",
      "}\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with AttributeError: 'DataFrame' object has no attribute 'ix'\",\n        \"detailsUri\": \"https://aka.ms/azureml-known-errors\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"AttributeError\",\n            \"message\": \"'DataFrame' object has no attribute 'ix'\",\n            \"stackTrace\": \"  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/95f2c341-21d2-4dc5-837e-5613c465f285/mounts/workspaceblobstore/azureml/95f2c341-21d2-4dc5-837e-5613c465f285/azureml-setup/context_manager_injector.py\\\", line 127, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/runpy.py\\\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/runpy.py\\\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"train.py\\\", line 118, in <module>\\n    X_train, X_test = X.ix[train_index], X.ix[test_index]\\n  File \\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/site-packages/pandas/core/generic.py\\\", line 5274, in __getattr__\\n    return object.__getattribute__(self, name)\\n\"\n        }\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with AttributeError: 'DataFrame' object has no attribute 'ix'\\\",\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-known-errors\\\",\\n        \\\"details\\\": [],\\n        \\\"debugInfo\\\": {\\n            \\\"type\\\": \\\"AttributeError\\\",\\n            \\\"message\\\": \\\"'DataFrame' object has no attribute 'ix'\\\",\\n            \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/95f2c341-21d2-4dc5-837e-5613c465f285/mounts/workspaceblobstore/azureml/95f2c341-21d2-4dc5-837e-5613c465f285/azureml-setup/context_manager_injector.py\\\\\\\", line 127, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/runpy.py\\\\\\\", line 263, in run_path\\\\n    pkg_name=pkg_name, script_name=fname)\\\\n  File \\\\\\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    mod_name, mod_spec, pkg_name, script_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/runpy.py\\\\\\\", line 85, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"train.py\\\\\\\", line 118, in <module>\\\\n    X_train, X_test = X.ix[train_index], X.ix[test_index]\\\\n  File \\\\\\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/site-packages/pandas/core/generic.py\\\\\\\", line 5274, in __getattr__\\\\n    return object.__getattribute__(self, name)\\\\n\\\"\\n        }\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-b7e8587566d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mpipeline_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    289\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                             step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[0;32m--> 291\u001b[0;31m                                                          raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    292\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtimeout_seconds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[0;32m--> 716\u001b[0;31m                                                raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The output streaming for the run interrupted.\\n\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with AttributeError: 'DataFrame' object has no attribute 'ix'\",\n        \"detailsUri\": \"https://aka.ms/azureml-known-errors\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"AttributeError\",\n            \"message\": \"'DataFrame' object has no attribute 'ix'\",\n            \"stackTrace\": \"  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/95f2c341-21d2-4dc5-837e-5613c465f285/mounts/workspaceblobstore/azureml/95f2c341-21d2-4dc5-837e-5613c465f285/azureml-setup/context_manager_injector.py\\\", line 127, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/runpy.py\\\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/runpy.py\\\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"train.py\\\", line 118, in <module>\\n    X_train, X_test = X.ix[train_index], X.ix[test_index]\\n  File \\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/site-packages/pandas/core/generic.py\\\", line 5274, in __getattr__\\n    return object.__getattribute__(self, name)\\n\"\n        }\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with AttributeError: 'DataFrame' object has no attribute 'ix'\\\",\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-known-errors\\\",\\n        \\\"details\\\": [],\\n        \\\"debugInfo\\\": {\\n            \\\"type\\\": \\\"AttributeError\\\",\\n            \\\"message\\\": \\\"'DataFrame' object has no attribute 'ix'\\\",\\n            \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/95f2c341-21d2-4dc5-837e-5613c465f285/mounts/workspaceblobstore/azureml/95f2c341-21d2-4dc5-837e-5613c465f285/azureml-setup/context_manager_injector.py\\\\\\\", line 127, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/runpy.py\\\\\\\", line 263, in run_path\\\\n    pkg_name=pkg_name, script_name=fname)\\\\n  File \\\\\\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    mod_name, mod_spec, pkg_name, script_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/runpy.py\\\\\\\", line 85, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"train.py\\\\\\\", line 118, in <module>\\\\n    X_train, X_test = X.ix[train_index], X.ix[test_index]\\\\n  File \\\\\\\"/azureml-envs/azureml_a07b3f6b915508b9807c3a8738c8bf38/lib/python3.6/site-packages/pandas/core/generic.py\\\\\\\", line 5274, in __getattr__\\\\n    return object.__getattribute__(self, name)\\\\n\\\"\\n        }\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [train_step, register_step]\n",
    "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "published_pipeline = pipeline.publish(\n",
    "    name=\"Training_Pipeline\")\n",
    "\n",
    "# Just to start test right away\n",
    "experiment = Experiment(workspace = ws, name = 'training-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example, designed to demonstrate the principle. In reality, you could build more sophisticated logic into the pipeline steps - for example, evaluating the model against some test data to calculate a performance metric like AUC or accuracy, comparing the metric to that of any previously registered versions of the model, and only registering the new model if it performs better.\n",
    "\n",
    "You can use the [Azure Machine Learning extension for Azure DevOps](https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.vss-services-azureml) to combine Azure ML pipelines with Azure DevOps pipelines (yes, it *is* confusing that they have the same name!) and integrate model retraining into a *continuous integration/continuous deployment (CI/CD)* process. For example you could use an Azure DevOps *build* pipeline to trigger an Azure ML pipeline that trains and registers a model, and when the model is registered it could trigger an Azure Devops *release* pipeline that deploys the model as a web service, along with the application or service that consumes the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a Score.py File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_name = 'porto-service'\n",
    "\n",
    "# Create a folder for the web service files\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "print(folder_name, 'folder created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $folder_name/score.py\n",
    "\n",
    "\"\"\"\n",
    "Copyright (C) Microsoft Corporation. All rights reserved.​\n",
    " ​\n",
    "Microsoft Corporation (“Microsoft”) grants you a nonexclusive, perpetual,\n",
    "royalty-free right to use, copy, and modify the software code provided by us\n",
    "(\"Software Code\"). You may not sublicense the Software Code or any use of it\n",
    "(except to your affiliates and to vendors to perform work on your behalf)\n",
    "through distribution, network access, service agreement, lease, rental, or\n",
    "otherwise. This license does not purport to express any claim of ownership over\n",
    "data you may have shared with Microsoft in the creation of the Software Code.\n",
    "Unless applicable law gives you more rights, Microsoft reserves all other\n",
    "rights not expressly granted herein, whether by implication, estoppel or\n",
    "otherwise. ​\n",
    " ​\n",
    "THE SOFTWARE CODE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS\n",
    "OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "MICROSOFT OR ITS LICENSORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n",
    "SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n",
    "PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR\n",
    "BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER\n",
    "IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "ARISING IN ANY WAY OUT OF THE USE OF THE SOFTWARE CODE, EVEN IF ADVISED OF THE\n",
    "POSSIBILITY OF SUCH DAMAGE.\n",
    "\"\"\"\n",
    "import json\n",
    "import numpy\n",
    "from azureml.core.model import Model\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "def init():\n",
    "    global LGBM_MODEL\n",
    "    # load the model from file into a global object\n",
    "    model_path = Model.get_model_path(\n",
    "        model_name=\"lgbm_binary_model.pkl\")\n",
    "    LGBM_MODEL = joblib.load(model_path)\n",
    "\n",
    "\n",
    "def run(raw_data, request_headers):\n",
    "    data = json.loads(raw_data)[\"data\"]\n",
    "    data = numpy.array(data)\n",
    "    result = LGBM_MODEL.predict(data)\n",
    "\n",
    "    # Demonstrate how we can log custom data into the Application Insights\n",
    "    # traces collection.\n",
    "    # The 'X-Ms-Request-id' value is generated internally and can be used to\n",
    "    # correlate a log entry with the Application Insights requests collection.\n",
    "    # The HTTP 'traceparent' header may be set by the caller to implement\n",
    "    # distributed tracing (per the W3C Trace Context proposed specification)\n",
    "    # and can be used to correlate the request to external systems.\n",
    "    print(('{{\"RequestId\":\"{0}\", '\n",
    "           '\"TraceParent\":\"{1}\", '\n",
    "           '\"NumberOfPredictions\":{2}}}'\n",
    "           ).format(\n",
    "               request_headers.get(\"X-Ms-Request-Id\", \"\"),\n",
    "               request_headers.get(\"Traceparent\", \"\"),\n",
    "               len(result)\n",
    "    ))\n",
    "\n",
    "    return {\"result\": result.tolist()}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test scoring\n",
    "    init()\n",
    "    TEST_ROW = '{\"data\":[[0,1,8,1,0,0,1,0,0,0,0,0,0,0,12,1,0,0,0.5,0.3,0.610327781,7,1,-1,0,-1,1,1,1,2,1,65,1,0.316227766,0.669556409,0.352136337,3.464101615,0.1,0.8,0.6,1,1,6,3,6,2,9,1,1,1,12,0,1,1,0,0,1],[4,2,5,1,0,0,0,0,1,0,0,0,0,0,5,1,0,0,0.9,0.5,0.771362431,4,1,-1,0,0,11,1,1,0,1,103,1,0.316227766,0.60632002,0.358329457,2.828427125,0.4,0.5,0.4,3,3,8,4,10,2,7,2,0,3,10,0,0,1,1,0,1]]}'  # NOQA: E501\n",
    "    PREDICTION = run(TEST_ROW, {})\n",
    "    print(\"Test result: \", PREDICTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
