{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning Pipeline with AutoMLStep (AutoML training in pipeline)\n",
    "This notebook demonstrates the use of **AutoMLStep** for training in Azure Machine Learning Pipeline.\n",
    "As secondary pipeline step, it also uses a **PythonScriptStep** for registering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this example we showcase how you can use AzureML Dataset to load data for AutoML via AML Pipeline. \n",
    "\n",
    "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you have executed the [configuration](https://aka.ms/pl-config) before running this notebook.\n",
    "\n",
    "In this notebook you will learn how to:\n",
    "1. Create an `Experiment` in an existing `Workspace`.\n",
    "2. Create or Attach existing AmlCompute to a workspace.\n",
    "3. Define data loading in a **TabularDataset**.\n",
    "4. Configure AutoML using **AutoMLConfig**.\n",
    "5. Configure **AutoMLStep** step for training\n",
    "6. Configure **PythonScriptStep** for registering the model in the Workspace\n",
    "6. Run the AML pipeline using AmlCompute\n",
    "7. Explore the results.\n",
    "8. Test the best fitted model.\n",
    "9. Publish the Pipeline in the Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Machine Learning and Pipeline SDK-specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.83\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import pkg_resources\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "from azureml.train.automl.runtime import AutoMLStep\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "Initialize a workspace object from persisted configuration. Make sure the config file is present at .\\config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cesardl-automl-ncentralus-demo-ws\n",
      "cesardl-automl-ncentralus-demo-ws-resgrp\n",
      "northcentralus\n",
      "381b38e9-9840-4719-a5a0-61d9585e1e91\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure ML experiment\n",
    "Let's create an experiment named \"automlstep-classif-porto\" and a folder to hold the training scripts. The script runs will be recorded under the experiment in Azure.\n",
    "\n",
    "The best practice is to use separate folders for scripts and its dependent files for each step and specify that folder as the `source_directory` for the step. This helps reduce the size of the snapshot created for the step (only the specific folder is snapshotted). Since changes in any files in the `source_directory` would trigger a re-upload of the snapshot, this helps keep the reuse of the step when there are no changes in the `source_directory` of the step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>automlstep-classif-porto</td><td>cesardl-automl-ncentralus-demo-ws</td><td><a href=\"https://ml.azure.com/experiments/automlstep-classif-porto?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: automlstep-classif-porto,\n",
       "Workspace: cesardl-automl-ncentralus-demo-ws)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a name for the run history container in the workspace.\n",
    "experiment_name = 'automlstep-classif-porto'\n",
    "project_folder = './project'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Attach an AmlCompute cluster\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for your AutoML run. In this tutorial, you get the default `AmlCompute` as your training compute resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing training cluster.\n",
      "Checking cluster status...\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "# Define remote compute target to use\n",
    "# Further docs on Remote Compute Target: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-remote\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "amlcompute_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "# CODE TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (***Optional***) Submit dataset file into DataStore (Azure Blob under the covers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading ../../../data/Place_here_the_Dataset_files.txt\n",
      "Uploading ../../../data/porto_seguro_safe_driver_prediction_train.csv\n",
      "Uploaded ../../../data/Place_here_the_Dataset_files.txt, 1 files out of an estimated total of 2\n",
      "Uploaded ../../../data/porto_seguro_safe_driver_prediction_train.csv, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_c40209a0f453435fa6f4329cc95f717e"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload(src_dir='../../../data/', \n",
    "                 target_path='Datasets/porto_seguro_safe_driver_prediction', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into Azure ML Dataset and Register into Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found and loaded from the Workspace\n"
     ]
    }
   ],
   "source": [
    "# Try to load the dataset from the Workspace. Otherwise, create it from the file in the HTTP URL\n",
    "found = False\n",
    "aml_dataset_name = \"porto_seguro_safe_driver_prediction_train\"\n",
    "\n",
    "if aml_dataset_name in ws.datasets.keys(): \n",
    "       found = True\n",
    "       dataset = ws.datasets[aml_dataset_name] \n",
    "       print(\"Dataset found and loaded from the Workspace\")\n",
    "       \n",
    "if not found:\n",
    "        # Create AML Dataset and register it into Workspace\n",
    "        print(\"Dataset does not exist in the current Workspace. It will be imported and registered.\")\n",
    "        \n",
    "        # Option A: Create AML Dataset from file in AML DataStore\n",
    "        datastore = ws.get_default_datastore()\n",
    "        dataset = Dataset.Tabular.from_delimited_files(path=datastore.path('Datasets/porto_seguro_safe_driver_prediction/porto_seguro_safe_driver_prediction_train.csv'))\n",
    "        data_origin_type = 'AMLDataStore'\n",
    "               \n",
    "        print(aml_dataset)\n",
    "                \n",
    "        #Register Dataset in Workspace\n",
    "        registration_method = 'SDK'  # or 'UI'\n",
    "        dataset = aml_dataset.register(workspace=ws,\n",
    "                                           name=aml_dataset_name,\n",
    "                                           description='Porto Seguro Safe Driver Prediction Train dataset file',\n",
    "                                           tags={'Registration-Method': registration_method, 'Data-Origin-Type': data_origin_type},\n",
    "                                           create_new_version=True)\n",
    "        \n",
    "        print(\"Dataset created from file and registered in the Workspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
      "0   7       0          2              2          5              1   \n",
      "\n",
      "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin       ...        \\\n",
      "0              0              0              1              0       ...         \n",
      "\n",
      "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
      "0           9           1           5           8               0   \n",
      "\n",
      "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
      "0               1               1               0               0   \n",
      "\n",
      "   ps_calc_20_bin  \n",
      "0               1  \n",
      "\n",
      "[1 rows x 59 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.take(1).to_pandas_dataframe().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin       ...        \\\n",
       "0              0              0              1              0       ...         \n",
       "1              0              0              0              1       ...         \n",
       "2              0              0              0              1       ...         \n",
       "3              0              1              0              0       ...         \n",
       "4              0              1              0              0       ...         \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(5).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segregate a Test dataset for later testing and creating a confusion matrix\n",
    "Split original AML Tabular Dataset in two test/train AML Tabular Datasets (using AML DS function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name and target column of the Dataset to create \n",
    "train_dataset_name = \"porto_seguro_safe_driver_prediction_train90\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'Datasets/porto_seguro_safe_driver_prediction/porto_seguro_safe_driver_prediction_train.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\",\n",
       "    \"RandomSplit\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"17771274-8b00-4ccf-a090-e0c9821eabdc\",\n",
       "    \"name\": \"porto_seguro_safe_driver_prediction_train90\",\n",
       "    \"version\": 2,\n",
       "    \"description\": \"Porto Seguro Safe Driver Prediction Train dataset file (90%)\",\n",
       "    \"tags\": {\n",
       "      \"Registration-Method\": \"SDK\",\n",
       "      \"Data-Origin-Type\": \"SPLIT\"\n",
       "    },\n",
       "    \"workspace\": \"Workspace.create(name='cesardl-automl-ncentralus-demo-ws', subscription_id='381b38e9-9840-4719-a5a0-61d9585e1e91', resource_group='cesardl-automl-ncentralus-demo-ws-resgrp')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split using Azure Tabular Datasets (Better for Remote Compute)\n",
    "# https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.tabulardataset?view=azure-ml-py#random-split-percentage--seed-none-\n",
    "\n",
    "train_dataset, test_dataset = dataset.random_split(0.9, seed=1)\n",
    "\n",
    "#Register Train Dataset (90%) after Split in Workspace\n",
    "registration_method = 'SDK'  # or 'UI'\n",
    "data_origin_type = 'SPLIT'\n",
    "train_dataset = train_dataset.register(workspace=ws,\n",
    "                                       name=train_dataset_name,\n",
    "                                       description='Porto Seguro Safe Driver Prediction Train dataset file (90%)',\n",
    "                                       tags={'Registration-Method': registration_method, 'Data-Origin-Type': data_origin_type},\n",
    "                                       create_new_version=True)\n",
    "\n",
    "# Load from Workspace\n",
    "train_dataset = ws.datasets[train_dataset_name] \n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train configuration in AutoMLConfig class\n",
    "This creates a general AutoML settings object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your AutoMLConfig object\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "automl_config = AutoMLConfig(\n",
    "                              # CODE TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The AML Pipeline\n",
    "\n",
    "### PipelineData objects\n",
    "\n",
    "The **PipelineData** object is a special kind of data reference that is used for interim storage locations that can be passed between pipeline steps, so we'll create one and use at as the output for the first step and the input for the second step. Note that we also need to pass it as a script argument so our code can access the datastore location referenced by the data reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_model_data\n"
     ]
    }
   ],
   "source": [
    "# Create your PipelineData objects needed to communicate data out of the steps:\n",
    "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "metrics_output_name = 'metrics_output'\n",
    "best_model_output_name = 'best_model_output'\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                            datastore=ds,\n",
    "                            pipeline_output_name=metrics_output_name,\n",
    "                            training_output=TrainingOutput(type='Metrics'))\n",
    "\n",
    "model_data = PipelineData(name='model_data',\n",
    "                          datastore=ds,\n",
    "                          pipeline_output_name=best_model_output_name,\n",
    "                          training_output=TrainingOutput(type='Model'))\n",
    "\n",
    "print(model_data.get_env_variable_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an AutoMLStep for training.\n",
    "Pipelines consist of one or more *steps*, which can be Python scripts, or specialized steps like an AutoMLStep for training or a data transfer step that copies data from one location to another. \n",
    "Each step can run in its own compute context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your AutoMLStep object providing your automl_config and outputs=[metrics_data, model_data] as parameters.\n",
    "\n",
    "# CODE TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a PythonScriptStep to register the model in the Workspace.\n",
    "\n",
    "Write/save the Python code to register the model in a file named register_model.py\n",
    "The script for the second step of the pipeline will load the model from where it was saved, and then register it in the workspace. It includes a single **model_folder** parameter that contains the path where the model was saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment, Conda-Dependencies and RunConfiguration for PythonScriptStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run config is ready\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import CondaDependencies, DEFAULT_CPU_IMAGE, RunConfiguration\n",
    "\n",
    "# Create an Environment for future usage\n",
    "custom_env = Environment(\"python-script-step-env\")\n",
    "custom_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "custom_env.docker.enabled = True \n",
    "custom_env.docker.base_image = azureml.core.runconfig.DEFAULT_CPU_IMAGE \n",
    "\n",
    "conda_dependencies = CondaDependencies.create(pip_packages=['azureml-sdk[automl]', 'applicationinsights'], #'azureml-explain-model'\n",
    "                                              conda_packages=['numpy==1.16.2'], \n",
    "                                              pin_sdk_version=False)\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "custom_env.python.conda_dependencies = conda_dependencies\n",
    "\n",
    "# Register the environment (To use it again)\n",
    "custom_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'python-script-step-env')\n",
    "\n",
    "# create a new RunConfig object\n",
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# Set compute target to AmlCompute\n",
    "conda_run_config.target = aml_remote_compute\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "conda_run_config.environment\n",
    "conda_run_config.environment = registered_env\n",
    "\n",
    "print('Run config is ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model step\n",
    "Script to register the model to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "scripts_folder=\"Scripts\"\n",
    "os.makedirs(scripts_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the register_model.py script file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Scripts/register_model.py\n"
     ]
    }
   ],
   "source": [
    "# Copy here the contents of the register_model.py.txt file provided in the Challenge\n",
    "# so you will generate the code to register the Model into the \"Scripts/register_model.py\" file when running this cell\n",
    "\n",
    "# CODE TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PythonScriptStep to run register_model.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to use in the Pipeline\n",
    "from azureml.pipeline.core import PipelineParameter\n",
    "\n",
    "# The model name with which to register the trained model in the workspace.\n",
    "model_name = \"porto-model-from-automlstep\"\n",
    "model_name_param = PipelineParameter(\"model_name\", default_value=model_name)\n",
    "\n",
    "# The Dataset name to relate with the model to register in the workspace.\n",
    "dataset_name_param = PipelineParameter(name=\"ds_name\", default_value=train_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "# Write your code to create the PythonScriptStep for Model registration\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "register_model_step = PythonScriptStep(\n",
    "                                       # CODE TBD\n",
    "                                      )\n",
    "\n",
    "register_model_step.run_after(automl_step)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example, designed to demonstrate the principle. In reality, you could build more sophisticated logic into the pipeline steps - for example, evaluating the model against some test data to calculate a performance metric like AUC or accuracy, comparing the metric to that of any previously registered versions of the model, and only registering the new model if it performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline and add the multiple steps into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "# CODE TBD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step automl_module [34b9fc4a][b2f9cb13-7a2c-4d79-ab3e-22da8c671c62], (This step will run and generate new outputs)Created step register_model [76f8bc02][b5ea4c91-a5fc-4a0b-829e-73542a6c6a9b], (This step will run and generate new outputs)\n",
      "\n",
      "Submitted PipelineRun 7df6727a-aabc-4428-bd0c-3fea0b07379d\n",
      "Link to Azure Machine Learning studio: https://ml.azure.com/experiments/automlstep-classif-porto/runs/7df6727a-aabc-4428-bd0c-3fea0b07379d?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\n",
      "Pipeline submitted for execution.\n"
     ]
    }
   ],
   "source": [
    "# Submit the Pipeline to start the run\n",
    "\n",
    "pipeline_run = experiment.submit(pipeline, pipeline_parameters={\n",
    "        \"ds_name\": train_dataset_name, \"model_name\": model_name})\n",
    "\n",
    "print(\"Pipeline submitted for execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba37f4f8e2b4e6785a3a5a46e7d8a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/automlstep-classif-porto/runs/7df6727a-aabc-4428-bd0c-3fea0b07379d?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\", \"run_id\": \"7df6727a-aabc-4428-bd0c-3fea0b07379d\", \"run_properties\": {\"run_id\": \"7df6727a-aabc-4428-bd0c-3fea0b07379d\", \"created_utc\": \"2020-03-06T03:08:17.329942Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{\\\"ds_name\\\":\\\"porto_seguro_safe_driver_prediction_train90\\\",\\\"model_name\\\":\\\"porto-model-from-automlstep\\\"}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7df6727a-aabc-4428-bd0c-3fea0b07379d/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=w6UDltVk7nFfmiM%2B978UfuFIfiK7nLF2dV8lR5N9A%2FA%3D&st=2020-03-06T03%3A03%3A36Z&se=2020-03-06T11%3A13%3A36Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7df6727a-aabc-4428-bd0c-3fea0b07379d/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=tXuO6lgQBU4WXYUn4fViQD1hoZu9%2Fh7H1UQBwzM3TK8%3D&st=2020-03-06T03%3A03%3A36Z&se=2020-03-06T11%3A13%3A36Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7df6727a-aabc-4428-bd0c-3fea0b07379d/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=fASujQbrXY9E4kY7TalQQrKdERjP4FjuzFa8v9j6Pyk%3D&st=2020-03-06T03%3A03%3A36Z&se=2020-03-06T11%3A13%3A36Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:05:19\"}, \"child_runs\": [{\"run_id\": \"e1670d4f-690d-45d5-af45-cc8da0a935e6\", \"name\": \"automl_module\", \"status\": \"Running\", \"start_time\": \"2020-03-06T03:12:14.57167Z\", \"created_time\": \"2020-03-06T03:08:20.031338Z\", \"end_time\": \"\", \"duration\": \"0:05:17\", \"run_number\": 128, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-03-06T03:08:20.031338Z\", \"is_reused\": \"\"}, {\"run_id\": \"\", \"name\": \"register_model\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2020-03-06 03:08:19Z] Submitting 1 runs, first five are: 34b9fc4a:e1670d4f-690d-45d5-af45-cc8da0a935e6\\n\", \"graph\": {\"datasource_nodes\": {\"591ba267\": {\"node_id\": \"591ba267\", \"name\": \"porto_seguro_safe_driver_prediction_train90\"}}, \"module_nodes\": {\"34b9fc4a\": {\"node_id\": \"34b9fc4a\", \"name\": \"automl_module\", \"status\": \"Running\", \"_is_reused\": false, \"run_id\": \"e1670d4f-690d-45d5-af45-cc8da0a935e6\"}, \"76f8bc02\": {\"node_id\": \"76f8bc02\", \"name\": \"register_model\", \"status\": \"NotStarted\"}}, \"edges\": [{\"source_node_id\": \"591ba267\", \"source_node_name\": \"porto_seguro_safe_driver_prediction_train90\", \"source_name\": \"data\", \"target_name\": \"training_data\", \"dst_node_id\": \"34b9fc4a\", \"dst_node_name\": \"automl_module\"}, {\"source_node_id\": \"34b9fc4a\", \"source_node_name\": \"automl_module\", \"source_name\": \"metrics_data\", \"target_name\": \"model_data\", \"dst_node_id\": \"76f8bc02\", \"dst_node_name\": \"register_model\"}, {\"source_node_id\": \"34b9fc4a\", \"source_node_name\": \"automl_module\", \"source_name\": \"metrics_data\", \"target_name\": \"model_data\", \"dst_node_id\": \"76f8bc02\", \"dst_node_name\": \"register_model\"}], \"child_runs\": [{\"run_id\": \"e1670d4f-690d-45d5-af45-cc8da0a935e6\", \"name\": \"automl_module\", \"status\": \"Running\", \"start_time\": \"2020-03-06T03:12:14.57167Z\", \"created_time\": \"2020-03-06T03:08:20.031338Z\", \"end_time\": \"\", \"duration\": \"0:05:17\", \"run_number\": 128, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-03-06T03:08:20.031338Z\", \"is_reused\": \"\"}, {\"run_id\": \"\", \"name\": \"register_model\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.83\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 7df6727a-aabc-4428-bd0c-3fea0b07379d\n",
      "Link to Portal: https://ml.azure.com/experiments/automlstep-classif-porto/runs/7df6727a-aabc-4428-bd0c-3fea0b07379d?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: e1670d4f-690d-45d5-af45-cc8da0a935e6\n",
      "Link to Portal: https://ml.azure.com/experiments/automlstep-classif-porto/runs/e1670d4f-690d-45d5-af45-cc8da0a935e6?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\n",
      "StepRun( automl_module ) Status: NotStarted\n",
      "StepRun( automl_module ) Status: Running\n",
      "\n",
      "StepRun(automl_module) Execution Summary\n",
      "=========================================\n",
      "StepRun( automl_module ) Status: Finished\n",
      "{'runId': 'e1670d4f-690d-45d5-af45-cc8da0a935e6', 'target': 'cpu-cluster', 'status': 'Completed', 'startTimeUtc': '2020-03-06T03:12:14.57167Z', 'endTimeUtc': '2020-03-06T03:14:54.091193Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '860a07d9-fda6-4223-82ab-9da021c9f34a', 'StepType': 'AutoMLStep', 'azureml.pipelinerunid': '7df6727a-aabc-4428-bd0c-3fea0b07379d', 'num_iterations': '1', 'training_type': 'TrainFull', 'acquisition_function': 'EI', 'metrics': 'accuracy', 'primary_metric': 'AUC_weighted', 'train_split': '0', 'MaxTimeSeconds': None, 'acquisition_parameter': '0', 'num_cross_validation': None, 'target': 'cpu-cluster', 'RawAMLSettingsString': \"{'name': 'placeholder', 'path': './project', 'subscription_id': '381b38e9-9840-4719-a5a0-61d9585e1e91', 'resource_group': 'cesardl-automl-ncentralus-demo-ws-resgrp', 'workspace_name': 'cesardl-automl-ncentralus-demo-ws', 'region': 'northcentralus', 'compute_target': None, 'spark_service': None, 'azure_service': None, 'iterations': 1, 'primary_metric': 'AUC_weighted', 'task_type': 'classification', 'data_script': None, 'validation_size': 0.0, 'n_cross_validations': None, 'y_min': None, 'y_max': None, 'num_classes': None, 'featurization': 'auto', 'preprocess': True, 'lag_length': 0, 'is_timeseries': False, 'max_cores_per_iteration': 1, 'max_concurrent_iterations': 1, 'iteration_timeout_minutes': None, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'experiment_timeout_minutes': None, 'experiment_exit_score': None, 'whitelist_models': ['LightGBM'], 'blacklist_algos': ['XGBoostClassifier', 'Prophet'], 'supported_models': ['SGD', 'GradientBoosting', 'SVM', 'LightGBM', 'LinearSVM', 'RandomForest', 'XGBoostClassifier', 'LogisticRegression', 'ExtremeRandomTrees', 'BernoulliNaiveBayes', 'KNN', 'AveragedPerceptronClassifier', 'MultinomialNaiveBayes', 'LinearSVMClassifier', 'TensorFlowDNN', 'TensorFlowLinearClassifier', 'DecisionTree'], 'auto_blacklist': True, 'blacklist_samples_reached': False, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'automated_ml_errors.log', 'show_warnings': False, 'model_explainability': False, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'enable_onnx_compatible_models': False, 'enable_split_onnx_featurizer_estimator_models': False, 'vm_type': None, 'telemetry_verbosity': 'INFO', 'send_telemetry': True, 'enable_dnn': False, 'force_text_dnn': False, 'enable_feature_sweeping': True, 'enable_early_stopping': True, 'early_stopping_n_iters': 10, 'metrics': None, 'enable_ensembling': False, 'enable_stack_ensembling': False, 'ensemble_iterations': None, 'enable_tf': False, 'enable_cache': True, 'enable_subsampling': False, 'subsample_seed': None, 'enable_nimbusml': False, 'enable_streaming': False, 'label_column_name': 'target', 'weight_column_name': None, 'cost_mode': 0, 'metric_operation': 'maximize'}\", 'AMLSettingsJsonString': '{\"name\": \"placeholder\", \"path\": \"./project\", \"subscription_id\": \"381b38e9-9840-4719-a5a0-61d9585e1e91\", \"resource_group\": \"cesardl-automl-ncentralus-demo-ws-resgrp\", \"workspace_name\": \"cesardl-automl-ncentralus-demo-ws\", \"region\": \"northcentralus\", \"compute_target\": null, \"spark_service\": null, \"azure_service\": null, \"iterations\": 1, \"primary_metric\": \"AUC_weighted\", \"task_type\": \"classification\", \"data_script\": null, \"validation_size\": 0.0, \"n_cross_validations\": null, \"y_min\": null, \"y_max\": null, \"num_classes\": null, \"featurization\": \"auto\", \"preprocess\": true, \"lag_length\": 0, \"is_timeseries\": false, \"max_cores_per_iteration\": 1, \"max_concurrent_iterations\": 1, \"iteration_timeout_minutes\": null, \"mem_in_mb\": null, \"enforce_time_on_windows\": false, \"experiment_timeout_minutes\": null, \"experiment_exit_score\": null, \"whitelist_models\": [\"LightGBM\"], \"blacklist_algos\": [\"XGBoostClassifier\", \"Prophet\"], \"supported_models\": [\"SGD\", \"GradientBoosting\", \"SVM\", \"LightGBM\", \"LinearSVM\", \"RandomForest\", \"XGBoostClassifier\", \"LogisticRegression\", \"ExtremeRandomTrees\", \"BernoulliNaiveBayes\", \"KNN\", \"AveragedPerceptronClassifier\", \"MultinomialNaiveBayes\", \"LinearSVMClassifier\", \"TensorFlowDNN\", \"TensorFlowLinearClassifier\", \"DecisionTree\"], \"auto_blacklist\": true, \"blacklist_samples_reached\": false, \"exclude_nan_labels\": true, \"verbosity\": 20, \"debug_log\": \"automated_ml_errors.log\", \"show_warnings\": false, \"model_explainability\": false, \"service_url\": null, \"sdk_url\": null, \"sdk_packages\": null, \"enable_onnx_compatible_models\": false, \"enable_split_onnx_featurizer_estimator_models\": false, \"vm_type\": null, \"telemetry_verbosity\": \"INFO\", \"send_telemetry\": true, \"enable_dnn\": false, \"force_text_dnn\": false, \"enable_feature_sweeping\": true, \"enable_early_stopping\": true, \"early_stopping_n_iters\": 10, \"metrics\": null, \"enable_ensembling\": false, \"enable_stack_ensembling\": false, \"ensemble_iterations\": null, \"enable_tf\": false, \"enable_cache\": true, \"enable_subsampling\": false, \"subsample_seed\": null, \"enable_nimbusml\": false, \"enable_streaming\": false, \"label_column_name\": \"target\", \"weight_column_name\": null, \"cost_mode\": 0, \"metric_operation\": \"maximize\"}', 'DataPrepJsonString': '{\\\\\"training_data\\\\\": {\\\\\"datasetId\\\\\": \\\\\"17771274-8b00-4ccf-a090-e0c9821eabdc\\\\\"}, \\\\\"datasets\\\\\": 0}', 'EnableSubsampling': 'False', 'runTemplate': 'AutoML', 'Orchestrator': 'automl', 'ClientType': 'Others', 'ClientSdkVersion': '', 'snapshotId': '860a07d9-fda6-4223-82ab-9da021c9f34a', 'SetupRunId': 'e1670d4f-690d-45d5-af45-cc8da0a935e6_setup', 'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": false, \"subsampling\": false, \"dataset_classes\": 2, \"dataset_features\": 58, \"dataset_samples\": 482198, \"single_frequency_class_detected\": false}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.e1670d4f-690d-45d5-af45-cc8da0a935e6/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=5QPUlcGLfqRNVATZ8f9Vk7LiisqB7RGrEbCJCIqdVSw%3D&st=2020-03-06T03%3A05%3A05Z&se=2020-03-06T11%3A15%3A05Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.e1670d4f-690d-45d5-af45-cc8da0a935e6/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=17NlS5wZiOUg6MWW%2FzVBUpUqua5b5LjAEG5p6yCchsI%3D&st=2020-03-06T03%3A05%3A05Z&se=2020-03-06T11%3A15%3A05Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.e1670d4f-690d-45d5-af45-cc8da0a935e6/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=CA1hF63mVsKD3JhhKUInQ99QvtFvKoU4bnpggu2EsyQ%3D&st=2020-03-06T03%3A05%3A05Z&se=2020-03-06T11%3A15%3A05Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18\n",
      "Link to Portal: https://ml.azure.com/experiments/automlstep-classif-porto/runs/c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\n",
      "StepRun( register_model ) Status: NotStarted\n",
      "StepRun( register_model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_c5a2821de41831a640fafa7043fe157be52673c769c63466e7e05e2ef652827f_d.txt\n",
      "========================================================================================================================\n",
      "2020-03-06T03:15:42Z Starting output-watcher...\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_7f9193beb11e1644acba4544f1646b5e\n",
      "a1298f4ce990: Already exists\n",
      "04a3282d9c4b: Already exists\n",
      "9b0d3db6dc03: Already exists\n",
      "8269c605f3f1: Already exists\n",
      "6504d449e70c: Already exists\n",
      "4e38f320d0d4: Already exists\n",
      "b0a763e8ee03: Already exists\n",
      "11917a028ca4: Already exists\n",
      "a6c378d11cbf: Already exists\n",
      "6cc007ad9140: Already exists\n",
      "6c1698a608f3: Already exists\n",
      "c59c728c018a: Pulling fs layer\n",
      "1c841a5580dc: Pulling fs layer\n",
      "ae6f6cbbb1d9: Pulling fs layer\n",
      "472bde7d072b: Pulling fs layer\n",
      "b70bf1636754: Pulling fs layer\n",
      "d23b5218a8ef: Pulling fs layer\n",
      "472bde7d072b: Waiting\n",
      "d23b5218a8ef: Waiting\n",
      "b70bf1636754: Waiting\n",
      "c59c728c018a: Verifying Checksum\n",
      "c59c728c018a: Download complete\n",
      "1c841a5580dc: Verifying Checksum\n",
      "1c841a5580dc: Download complete\n",
      "c59c728c018a: Pull complete\n",
      "ae6f6cbbb1d9: Download complete\n",
      "1c841a5580dc: Pull complete\n",
      "472bde7d072b: Download complete\n",
      "d23b5218a8ef: Download complete\n",
      "ae6f6cbbb1d9: Pull complete\n",
      "472bde7d072b: Pull complete\n",
      "b70bf1636754: Verifying Checksum\n",
      "b70bf1636754: Download complete\n",
      "b70bf1636754: Pull complete\n",
      "d23b5218a8ef: Pull complete\n",
      "Digest: sha256:8ce411709646f4d42a29ed8a4298f7917ad87125cf11e576982bd6db827ce301\n",
      "Status: Downloaded newer image for cesardlautoma5f87185.azurecr.io/azureml/azureml_7f9193beb11e1644acba4544f1646b5e:latest\n",
      "aa00680ae7896699fcce69062a25014739963a8727a2252680e0b1a435fd5316\n",
      "2020/03/06 03:16:27 Version: 3.0.01110.0001 Branch: master Commit: ab88b58d\n",
      "2020/03/06 03:16:28 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/03/06 03:16:28 sshd runtime has already been installed in the container\n",
      "ssh-keygen: /azureml-envs/azureml_46c2e1decd6dcdd0c8e693211d39dc0d/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_46c2e1decd6dcdd0c8e693211d39dc0d/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "bash: /azureml-envs/azureml_46c2e1decd6dcdd0c8e693211d39dc0d/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "bash: /azureml-envs/azureml_46c2e1decd6dcdd0c8e693211d39dc0d/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_c5a2821de41831a640fafa7043fe157be52673c769c63466e7e05e2ef652827f_d.txt\n",
      "===============================================================================================================\n",
      "bash: /azureml-envs/azureml_46c2e1decd6dcdd0c8e693211d39dc0d/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting job preparation. Current time:2020-03-06T03:16:34.576764\n",
      "Extracting the control code.\n",
      "Creating directory: azureml-logs/\n",
      "Retrieving project from snapshot: 86e77635-207b-4376-a923-4ba0a77fbefc\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 102\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "Download from datastores if requested.\n",
      "Download or mount from datasets if requested.\n",
      "Job preparation is complete. Current time:2020-03-06T03:16:39.213364\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "bash: /azureml-envs/azureml_46c2e1decd6dcdd0c8e693211d39dc0d/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "bash: /azureml-envs/azureml_46c2e1decd6dcdd0c8e693211d39dc0d/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 162\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ register_model.py ] with arguments: ['--model_name', 'porto-model-from-automlstep', '--model_path', '/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/mounts/workspaceblobstore/azureml/e1670d4f-690d-45d5-af45-cc8da0a935e6/model_data', '--ds_name', 'porto_seguro_safe_driver_prediction_train90']\n",
      "After variable expansion, calling script [ register_model.py ] with arguments: ['--model_name', 'porto-model-from-automlstep', '--model_path', '/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/mounts/workspaceblobstore/azureml/e1670d4f-690d-45d5-af45-cc8da0a935e6/model_data', '--ds_name', 'porto_seguro_safe_driver_prediction_train90']\n",
      "\n",
      "Argument 1(model_name): porto-model-from-automlstep\n",
      "Argument 2(model_path): /mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/mounts/workspaceblobstore/azureml/e1670d4f-690d-45d5-af45-cc8da0a935e6/model_data\n",
      "Argument 3(ds_name): porto_seguro_safe_driver_prediction_train90\n",
      "Registering model porto-model-from-automlstep\n",
      "Registered version 7 of model porto-model-from-automlstep\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.0032634735107421875 seconds\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 162\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_c5a2821de41831a640fafa7043fe157be52673c769c63466e7e05e2ef652827f_d.txt\n",
      "===============================================================================================================\n",
      "bash: /azureml-envs/azureml_46c2e1decd6dcdd0c8e693211d39dc0d/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "Starting job release. Current time:2020-03-06T03:16:55.183200\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 194\n",
      "Job release is complete. Current time:2020-03-06T03:16:57.173772\n",
      "\n",
      "StepRun(register_model) Execution Summary\n",
      "==========================================\n",
      "StepRun( register_model ) Status: Finished\n",
      "{'runId': 'c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18', 'target': 'cpu-cluster', 'status': 'Completed', 'startTimeUtc': '2020-03-06T03:15:42.042793Z', 'endTimeUtc': '2020-03-06T03:17:10.223445Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '86e77635-207b-4376-a923-4ba0a77fbefc', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': '7df6727a-aabc-4428-bd0c-3fea0b07379d', '_azureml.ComputeTargetType': 'amlcompute', 'AzureML.DerivedImageName': 'azureml/azureml_7f9193beb11e1644acba4544f1646b5e', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '17771274-8b00-4ccf-a090-e0c9821eabdc'}, 'consumptionDetails': {'type': 'Reference'}}], 'runDefinition': {'script': 'register_model.py', 'useAbsolutePath': False, 'arguments': ['--model_name', '$AML_PARAMETER_model_name', '--model_path', '$AZUREML_DATAREFERENCE_model_data', '--ds_name', '$AML_PARAMETER_ds_name'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpu-cluster', 'dataReferences': {'model_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/e1670d4f-690d-45d5-af45-cc8da0a935e6/model_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment automlstep-classif-porto Environment', 'version': 'Autosave_2020-03-02T21:37:38Z_103ec7c4', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk[automl]', 'applicationinsights']}, 'numpy==1.16.2'], 'name': 'azureml_46c2e1decd6dcdd0c8e693211d39dc0d'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'AML_PARAMETER_model_name': 'porto-model-from-automlstep', 'AML_PARAMETER_ds_name': 'porto_seguro_safe_driver_prediction_train90'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_c5a2821de41831a640fafa7043fe157be52673c769c63466e7e05e2ef652827f_d.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/azureml-logs/55_azureml-execution-tvmps_c5a2821de41831a640fafa7043fe157be52673c769c63466e7e05e2ef652827f_d.txt?sv=2019-02-02&sr=b&sig=157YF8UMjKHLbMZEl2Qwy%2Btpwp%2FyKqHgEZp2xVj3OBI%3D&st=2020-03-06T03%3A07%3A15Z&se=2020-03-06T11%3A17%3A15Z&sp=r', 'azureml-logs/65_job_prep-tvmps_c5a2821de41831a640fafa7043fe157be52673c769c63466e7e05e2ef652827f_d.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/azureml-logs/65_job_prep-tvmps_c5a2821de41831a640fafa7043fe157be52673c769c63466e7e05e2ef652827f_d.txt?sv=2019-02-02&sr=b&sig=5d21CX2VYCD7wNvEAlfyUIvqAZvvzXm1LoYDWg%2BuFjs%3D&st=2020-03-06T03%3A07%3A15Z&se=2020-03-06T11%3A17%3A15Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=7hFLNxcw8%2FrPR1d64ZaXShR9ql7k5rpmEuCRQ0lBAfE%3D&st=2020-03-06T03%3A07%3A15Z&se=2020-03-06T11%3A17%3A15Z&sp=r', 'azureml-logs/75_job_post-tvmps_c5a2821de41831a640fafa7043fe157be52673c769c63466e7e05e2ef652827f_d.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/azureml-logs/75_job_post-tvmps_c5a2821de41831a640fafa7043fe157be52673c769c63466e7e05e2ef652827f_d.txt?sv=2019-02-02&sr=b&sig=NFoNsau%2FD2xElWSDU0OkBKSWx%2F9A4gncrKd7z%2BHaXBg%3D&st=2020-03-06T03%3A07%3A15Z&se=2020-03-06T11%3A17%3A15Z&sp=r', 'azureml-logs/process_info.json': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=LRN8kr9O9aDcwOM8LYqA5oqiS8J1OTk%2BaRemri1J3Sk%3D&st=2020-03-06T03%3A07%3A15Z&se=2020-03-06T11%3A17%3A15Z&sp=r', 'azureml-logs/process_status.json': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=W6B1GE%2B9f%2BEjb4FRWHe55%2Bf4CRULGNC3QJFy2504te8%3D&st=2020-03-06T03%3A07%3A15Z&se=2020-03-06T11%3A17%3A15Z&sp=r', 'logs/azureml/162_azureml.log': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/logs/azureml/162_azureml.log?sv=2019-02-02&sr=b&sig=h8LxuW%2Bq1zsqPedkOHC0o%2BmzTj5a5gyTWQrJEdGuxHE%3D&st=2020-03-06T03%3A07%3A15Z&se=2020-03-06T11%3A17%3A15Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=1xu8gmYW4ErZ0HHov9rG0YfjfSAFkukHmhrTZAGFTzk%3D&st=2020-03-06T03%3A07%3A15Z&se=2020-03-06T11%3A17%3A15Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=P58FE%2F5coRpNBV7o0WssadfZXPwNOwZp%2BVlwKisa1nk%3D&st=2020-03-06T03%3A07%3A15Z&se=2020-03-06T11%3A17%3A15Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=tmKaVZINBrMPALLLM4Y0mnVUe%2FAR7tz7K%2FRB6ez4XBg%3D&st=2020-03-06T03%3A07%3A15Z&se=2020-03-06T11%3A17%3A15Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=qfoHIiPUMBUZqO%2F8vrfFgLhHLkO9labHOjDFmdXPDZM%3D&st=2020-03-06T03%3A07%3A15Z&se=2020-03-06T11%3A17%3A15Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.c8fcd14f-a1c2-4207-8e31-9cd0c7cadd18/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=RjrRx3pAhvtKzL2ZOr7q308j8aVCSmiLEE5pGfNvVOw%3D&st=2020-03-06T03%3A07%3A15Z&se=2020-03-06T11%3A17%3A15Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '7df6727a-aabc-4428-bd0c-3fea0b07379d', 'status': 'Completed', 'startTimeUtc': '2020-03-06T03:08:19.169911Z', 'endTimeUtc': '2020-03-06T03:17:15.177671Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"ds_name\":\"porto_seguro_safe_driver_prediction_train90\",\"model_name\":\"porto-model-from-automlstep\"}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7df6727a-aabc-4428-bd0c-3fea0b07379d/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=AU2c7GLPh9llfi3L%2FU6V4R8zmajD6V1tIRZ%2FuODdKpY%3D&st=2020-03-06T03%3A07%3A17Z&se=2020-03-06T11%3A17%3A17Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7df6727a-aabc-4428-bd0c-3fea0b07379d/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=PkZYM9Elq4rQOYqH0vmL04%2FhAbWyDpHyMwxw89wLi84%3D&st=2020-03-06T03%3A07%3A17Z&se=2020-03-06T11%3A17%3A17Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7df6727a-aabc-4428-bd0c-3fea0b07379d/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=w%2FjVF6jrBOW6ZofiqzV%2FP0m6R5PcgvF%2B%2BnJEqCjSbBA%3D&st=2020-03-06T03%3A07%3A17Z&se=2020-03-06T11%3A17%3A17Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Results from Pipeline\n",
    "\n",
    "### Retrieve the metrics of all child runs\n",
    "Outputs of above run can be used as inputs of other steps in pipeline. In this tutorial, we will examine the outputs by retrieve output data and running some tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_output = pipeline_run.get_pipeline_output(metrics_output_name)\n",
    "num_file_downloaded = metrics_output.download('.', show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(metrics_output._path_on_datastore) as f:  \n",
    "   metrics_output_result = f.read()\n",
    "    \n",
    "deserialized_metrics_output = json.loads(metrics_output_result)\n",
    "df = pd.DataFrame(deserialized_metrics_output)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve info about the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_output = pipeline_run.get_pipeline_output(best_model_output_name)\n",
    "num_file_downloaded = best_model_output.download('.', show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(best_model_output._path_on_datastore, \"rb\" ) as f:\n",
    "    best_model = pickle.load(f)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "#### Prepare the Test DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_dataset.to_pandas_dataframe()\n",
    "print(test_df.shape)\n",
    "\n",
    "test_df = test_df[pd.notnull(test_df['target'])]\n",
    "\n",
    "if 'target' in test_df.columns:\n",
    "    y_test = test_df[['target']]\n",
    "    X_test = test_df.drop(['target'], axis=1)\n",
    "\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Our Best Fitted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the best model making predictions with the test dataset\n",
    "y_predictions = best_model.predict(X_test)\n",
    "\n",
    "print('10 predictions: ')\n",
    "print(y_predictions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy with Scikit-Learn model:')\n",
    "print(accuracy_score(y_test, y_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate AUC with Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_predictions)\n",
    "print('AUC (Area Under the Curve) with Test dataset:')\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Confusion Matrix\n",
    "We will use confusion matrix to see how our model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "cm = ConfusionMatrix(y_test['target'], y_predictions)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "cm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the Pipeline\n",
    "Now that you've created a pipeline and verified it works, you can publish it as a REST service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE TBD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigger the AML Pipeline by using the Pipeline REST Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. A real application would require a service principal with which to be authenticated, but to test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print(auth_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to call the REST interface. The pipeline runs asynchronously, so you'll get an identifier back, which you can use to track the pipeline experiment as it runs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The REST Endpoint\n",
    "Note that the published pipeline has an endpoint, which you can see in the Endpoints page (on the Pipeline Endpoints tab) in Azure Machine Learning studio. You can also find its URI as a property of the published pipeline object.\n",
    "So, you could also copy that REST Endpoint from the AML portal and paste it like here:\n",
    "\n",
    "rest_endpoint = \"Your copied REST Endpoint here\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you have the run ID, you can use the RunDetails widget to view the experiment as it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# CODE TBD TO CREATE PipelineRun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps!\n",
    "You can use the Azure Machine Learning extension for Azure DevOps to combine Azure ML pipelines with Azure DevOps pipelines (yes, it is confusing that they have the same name!) and integrate model retraining into a continuous integration/continuous deployment (CI/CD) process. For example you could use an Azure DevOps build pipeline to trigger an Azure ML pipeline that trains and registers a model, and when the model is registered it could trigger an Azure Devops release pipeline that deploys the model as a web service, along with the application or service that consumes the model."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "sanpil"
   }
  ],
  "category": "tutorial",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "Custom"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "Automated Machine Learning"
  ],
  "friendly_name": "How to use AutoMLStep with AML Pipelines",
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "order_index": 11,
  "star_tag": [
   "featured"
  ],
  "tags": [
   "None"
  ],
  "task": "Demonstrates the use of AutoMLStep"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}