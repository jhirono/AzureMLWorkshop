{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porto Seguro's Safe Driving Prediction (AutoML Local Compute)\n",
    "\n",
    "Porto Seguro, one of Brazil’s largest auto and homeowner insurance companies, completely agrees. Inaccuracies in car insurance company’s claim predictions raise the cost of insurance for good drivers and reduce the price for bad ones.\n",
    "\n",
    "In the [Porto Seguro Safe Driver Prediction competition](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction), the challenge is to build a model that predicts the probability that a driver will initiate an auto insurance claim in the next year. While Porto Seguro has used machine learning for the past 20 years, they’re looking to Kaggle’s machine learning community to explore new, more powerful methods. A more accurate prediction will allow them to further tailor their prices, and hopefully make auto insurance coverage more accessible to more drivers.\n",
    "\n",
    "Lucky for you, a machine learning model was built to solve the Porto Seguro problem by the data scientist on your team. The solution notebook has steps to load data, split the data into test and train sets, train, evaluate and save a LightGBM model that will be used for the future challenges.\n",
    "\n",
    "#### Hint: use shift + enter to run the code cells below. Once the cell turns from [*] to [#], you can be sure the cell has run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Needed Packages\n",
    "\n",
    "Import the packages needed for this solution notebook. The most widely used package for machine learning is [scikit-learn](https://scikit-learn.org/stable/), [pandas](https://pandas.pydata.org/docs/getting_started/index.html#getting-started), and [numpy](https://numpy.org/). These packages have various features, as well as a lot of clustering, regression and classification algorithms that make it a good choice for data mining and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get Azure ML Workspace to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "# Get Workspace defined in by default config.json file\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Azure ML Dataset into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595212, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin       ...        \\\n",
       "0              0              0              1              0       ...         \n",
       "1              0              0              0              1       ...         \n",
       "2              0              0              0              1       ...         \n",
       "3              0              1              0              0       ...         \n",
       "4              0              1              0              0       ...         \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "aml_dataset = ws.datasets['porto_seguro_safe_driver_prediction_train']\n",
    "\n",
    "# Use Pandas DataFrame just to sneak peak some data and schema\n",
    "data_df = aml_dataset.to_pandas_dataframe()\n",
    "# .to_pandas_dataframe().dropna()\n",
    "print(data_df.shape)\n",
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train and Validatation Sets\n",
    "\n",
    "Partitioning data into training, validation, and holdout sets allows you to develop highly accurate models that are relevant to data that you collect in the future, not just the data the model was trained on. \n",
    "\n",
    "In machine learning, features are the measurable property of the object you’re trying to analyze. Typically, features are the columns of the data that you are training your model with minus the label. In machine learning, a label (categorical) or target (regression) is the output you get from your model after training it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.761690e+05</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.000000</td>\n",
       "      <td>476169.00000</td>\n",
       "      <td>476169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.437524e+05</td>\n",
       "      <td>0.036506</td>\n",
       "      <td>1.900976</td>\n",
       "      <td>1.359454</td>\n",
       "      <td>4.422102</td>\n",
       "      <td>0.417014</td>\n",
       "      <td>0.405703</td>\n",
       "      <td>0.393887</td>\n",
       "      <td>0.256571</td>\n",
       "      <td>0.164015</td>\n",
       "      <td>...</td>\n",
       "      <td>5.440537</td>\n",
       "      <td>1.440531</td>\n",
       "      <td>2.872552</td>\n",
       "      <td>7.538813</td>\n",
       "      <td>0.122163</td>\n",
       "      <td>0.628290</td>\n",
       "      <td>0.553726</td>\n",
       "      <td>0.287415</td>\n",
       "      <td>0.34905</td>\n",
       "      <td>0.153252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.295313e+05</td>\n",
       "      <td>0.187546</td>\n",
       "      <td>1.984314</td>\n",
       "      <td>0.665377</td>\n",
       "      <td>2.699939</td>\n",
       "      <td>0.493321</td>\n",
       "      <td>1.351893</td>\n",
       "      <td>0.488611</td>\n",
       "      <td>0.436741</td>\n",
       "      <td>0.370290</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333257</td>\n",
       "      <td>1.202623</td>\n",
       "      <td>1.695711</td>\n",
       "      <td>2.747018</td>\n",
       "      <td>0.327474</td>\n",
       "      <td>0.483262</td>\n",
       "      <td>0.497106</td>\n",
       "      <td>0.452557</td>\n",
       "      <td>0.47667</td>\n",
       "      <td>0.360231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.717290e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.432460e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.115723e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.488027e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         target      ps_ind_01  ps_ind_02_cat  \\\n",
       "count  4.761690e+05  476169.000000  476169.000000  476169.000000   \n",
       "mean   7.437524e+05       0.036506       1.900976       1.359454   \n",
       "std    4.295313e+05       0.187546       1.984314       0.665377   \n",
       "min    7.000000e+00       0.000000       0.000000      -1.000000   \n",
       "25%    3.717290e+05       0.000000       0.000000       1.000000   \n",
       "50%    7.432460e+05       0.000000       1.000000       1.000000   \n",
       "75%    1.115723e+06       0.000000       3.000000       2.000000   \n",
       "max    1.488027e+06       1.000000       7.000000       4.000000   \n",
       "\n",
       "           ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  ps_ind_06_bin  \\\n",
       "count  476169.000000  476169.000000  476169.000000  476169.000000   \n",
       "mean        4.422102       0.417014       0.405703       0.393887   \n",
       "std         2.699939       0.493321       1.351893       0.488611   \n",
       "min         0.000000      -1.000000      -1.000000       0.000000   \n",
       "25%         2.000000       0.000000       0.000000       0.000000   \n",
       "50%         4.000000       0.000000       0.000000       0.000000   \n",
       "75%         6.000000       1.000000       0.000000       1.000000   \n",
       "max        11.000000       1.000000       6.000000       1.000000   \n",
       "\n",
       "       ps_ind_07_bin  ps_ind_08_bin       ...           ps_calc_11  \\\n",
       "count  476169.000000  476169.000000       ...        476169.000000   \n",
       "mean        0.256571       0.164015       ...             5.440537   \n",
       "std         0.436741       0.370290       ...             2.333257   \n",
       "min         0.000000       0.000000       ...             0.000000   \n",
       "25%         0.000000       0.000000       ...             4.000000   \n",
       "50%         0.000000       0.000000       ...             5.000000   \n",
       "75%         1.000000       0.000000       ...             7.000000   \n",
       "max         1.000000       1.000000       ...            19.000000   \n",
       "\n",
       "          ps_calc_12     ps_calc_13     ps_calc_14  ps_calc_15_bin  \\\n",
       "count  476169.000000  476169.000000  476169.000000   476169.000000   \n",
       "mean        1.440531       2.872552       7.538813        0.122163   \n",
       "std         1.202623       1.695711       2.747018        0.327474   \n",
       "min         0.000000       0.000000       0.000000        0.000000   \n",
       "25%         1.000000       2.000000       6.000000        0.000000   \n",
       "50%         1.000000       3.000000       7.000000        0.000000   \n",
       "75%         2.000000       4.000000       9.000000        0.000000   \n",
       "max        10.000000      13.000000      23.000000        1.000000   \n",
       "\n",
       "       ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "count   476169.000000   476169.000000   476169.000000    476169.00000   \n",
       "mean         0.628290        0.553726        0.287415         0.34905   \n",
       "std          0.483262        0.497106        0.452557         0.47667   \n",
       "min          0.000000        0.000000        0.000000         0.00000   \n",
       "25%          0.000000        0.000000        0.000000         0.00000   \n",
       "50%          1.000000        1.000000        0.000000         0.00000   \n",
       "75%          1.000000        1.000000        1.000000         1.00000   \n",
       "max          1.000000        1.000000        1.000000         1.00000   \n",
       "\n",
       "       ps_calc_20_bin  \n",
       "count   476169.000000  \n",
       "mean         0.153252  \n",
       "std          0.360231  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.000000  \n",
       "max          1.000000  \n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split in train/validation datasets (Validation=20%, Train=80%)\n",
    "# Only split in test/train\n",
    "train_df, validation_df = train_test_split(data_df, test_size=0.2, random_state=0)\n",
    "train_df.describe()\n",
    "\n",
    "# If seggregating the Y from X features\n",
    "# features = data_df.drop('target', axis = 1)\n",
    "#labels = np.array(data_df['target'])\n",
    "#features_train, features_valid, labels_train, labels_valid = train_test_split(features, labels, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Azure AutoML automatically searching for the 'best model' (Best algorithms and best hyper-parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List and select primary metric to drive the AutoML classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUC_weighted',\n",
       " 'norm_macro_recall',\n",
       " 'precision_score_weighted',\n",
       " 'accuracy',\n",
       " 'average_precision_score_weighted']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train import automl\n",
    "\n",
    "# List of possible primary metrics is here:\n",
    "# https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#primary-metric\n",
    "    \n",
    "# Get a list of valid metrics for your given task\n",
    "automl.utilities.get_primary_metrics('classification')\n",
    "\n",
    "# I'll use 'accuracy' as primary metric (Closer to 1.00 is better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define AutoML Experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# You can provide additional settings as a **kwargs parameter for the AutoMLConfig object\n",
    "# automl_settings = {\n",
    "#     \"whitelist_models\": 'XGBoostClassifier'\n",
    "# }\n",
    "\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "automl_config = AutoMLConfig(task='classification',\n",
    "                             primary_metric='AUC_weighted',\n",
    "                             # experiment_timeout_minutes= 20,                            \n",
    "                             training_data=train_df,\n",
    "                             validation_data=validation_df,\n",
    "                             label_column_name=\"target\", \n",
    "                             # blacklist_models='XGBoostClassifier', \n",
    "                             # iteration_timeout_minutes= 5,                                                    \n",
    "                             enable_early_stopping= True,\n",
    "                             featurization= 'auto',\n",
    "                             debug_log='automated_ml_errors.log',\n",
    "                             verbosity= logging.INFO,\n",
    "                             enable_onnx_compatible_models=False\n",
    "                             # **automl_settings\n",
    "                             )\n",
    "\n",
    "# Explanation of Settings: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#configure-your-experiment-settings\n",
    "\n",
    "# AutoMLConfig info on: \n",
    "# https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment with multiple child runs under the covers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK_local_porto_seguro_driver_pred\n",
      "Running on local machine\n",
      "Parent Run ID: AutoML_25b31b12-1d1c-44ee-b549-3469323ef4d9\n",
      "\n",
      "Current status: DatasetFeaturization. Beginning to featurize the dataset.\n",
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the dataset.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS SUMMARY:\n",
      "For more details, use API: run.get_guardrails()\n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       ALERTED\n",
      "DESCRIPTION:  Classes in the training data are imbalanced.\n",
      "\n",
      "TYPE:         Missing values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  There were no missing values found in the training data.\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:00:12       0.6226    0.6226\n",
      "         1   MaxAbsScaler SGD                               0:00:08       0.5747    0.6226\n",
      "         2   StandardScalerWrapper LightGBM                 0:00:12       0.6272    0.6272\n",
      "         3   MaxAbsScaler RandomForest                      0:00:15       0.6073    0.6272\n",
      "         4   MaxAbsScaler SGD                               0:00:12       0.5771    0.6272\n",
      "         5   MaxAbsScaler ExtremeRandomTrees                0:00:13       0.5983    0.6272\n",
      "         6   MaxAbsScaler SGD                               0:00:10       0.5604    0.6272\n",
      "         7   StandardScalerWrapper ExtremeRandomTrees       0:00:26       0.5958    0.6272\n",
      "         8   MaxAbsScaler RandomForest                      0:00:14       0.6098    0.6272\n",
      "         9   MaxAbsScaler LightGBM                          0:00:10       0.6198    0.6272\n",
      "        10   MaxAbsScaler BernoulliNaiveBayes               0:00:09       0.6141    0.6272\n",
      "        11   MaxAbsScaler SGD                               0:00:08       0.6095    0.6272\n",
      "        12   MaxAbsScaler LightGBM                          0:00:20       0.6264    0.6272\n",
      "        13   MaxAbsScaler ExtremeRandomTrees                0:00:33       0.6044    0.6272\n",
      "        14   MaxAbsScaler ExtremeRandomTrees                0:00:25       0.6186    0.6272\n",
      "        15   MaxAbsScaler SGD                               0:00:09       0.6261    0.6272\n",
      "        16   MaxAbsScaler LightGBM                          0:00:10       0.6188    0.6272\n",
      "        17   StandardScalerWrapper BernoulliNaiveBayes      0:00:08       0.6140    0.6272\n",
      "        18   MaxAbsScaler RandomForest                      0:00:17       0.5890    0.6272\n",
      "        19   "
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = \"SDK_local_porto_seguro_driver_pred\"\n",
    "print(experiment_name)\n",
    "\n",
    "experiment = Experiment(workspace=ws, \n",
    "                        name=experiment_name)\n",
    "\n",
    "run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore results with Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the results of automatic training with a Jupyter widget: https://docs.microsoft.com/en-us/python/api/azureml-widgets/azureml.widgets?view=azure-ml-py\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the 'Best' Scikit-Learn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = run.get_output()\n",
    "print(best_run)\n",
    "print('--------')\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See files associated with the 'Best run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run.get_file_names())\n",
    "\n",
    "# best_run.download_file('azureml-logs/70_driver_log.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Dataset from AML Workspace\n",
    "ISSUE: The Test dataset doesn't have any label column..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_test_dataset = ws.datasets['porto_seguro_safe_driver_prediction_test']\n",
    "\n",
    "test_df = aml_test_dataset.to_pandas_dataframe()\n",
    "# .to_pandas_dataframe().dropna()\n",
    "print(test_df.shape)\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Validation or Test Data: Extract X values (feature columns) from test dataset and convert to NumPi array for predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Remove Label/y column\n",
    "if 'target' in validation_df.columns:\n",
    "    y_validation_df = validation_df.pop('target')\n",
    "\n",
    "x_validation_df = validation_df\n",
    "\n",
    "x_validation_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model into memory\n",
    "import joblib\n",
    "fitted_model = joblib.load('model.pkl')\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions in bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the best model making predictions with the test dataset\n",
    "y_predictions = fitted_model.predict(x_validation_df)\n",
    "\n",
    "print('10 predictions: ')\n",
    "print(y_predictions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "Evaluating performance is an essential task in machine learning. In this case, because this is a classification problem, the data scientist elected to use an AUC - ROC Curve. When we need to check or visualize the performance of the multi - class classification problem, we use AUC (Area Under The Curve) ROC (Receiver Operating Characteristics) curve. It is one of the most important evaluation metrics for checking any classification model’s performance.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Oxana_Trifonova/publication/276079439/figure/fig2/AS:614187332034565@1523445079168/An-example-of-ROC-curves-with-good-AUC-09-and-satisfactory-AUC-065-parameters.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 12px; width: 320px; height: 239px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Accuracy with Validation or Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy with Scikit-Learn model:')\n",
    "print(accuracy_score(y_validation_df, y_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_validation_df, y_predictions)\n",
    "print('AUC (Area Under the Curve) with Scikit-Learn model:')\n",
    "metrics.auc(fpr, tpr)\n",
    "\n",
    "# AUC with plain LightGBM was: 0.6374553321494826 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Model in AML Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
